{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feedforward (Sequential dense net on pima indians data set)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NimishaTiwari/Machine_learning_2K20_ACRO/blob/master/feedforward_(Sequential_dense_net_on_pima_indians_data_set).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVS8Vp-ntc4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr9UHMptFl9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21PTNEFuB-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset\n",
        "dataset = loadtxt('/content/pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmcPosykvTrX",
        "colab_type": "code",
        "outputId": "e2f50071-313d-4b98-8b37-ea970b53dff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load the dataset\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=8, activation='relu'))\n",
        "model.add(Dense(25, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=750, batch_size=10)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/750\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "768/768 [==============================] - 2s 2ms/step - loss: 2.3447 - acc: 0.5117\n",
            "Epoch 2/750\n",
            "768/768 [==============================] - 0s 429us/step - loss: 0.6797 - acc: 0.6354\n",
            "Epoch 3/750\n",
            "768/768 [==============================] - 0s 402us/step - loss: 0.6830 - acc: 0.6302\n",
            "Epoch 4/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.6607 - acc: 0.6680\n",
            "Epoch 5/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.6264 - acc: 0.6745\n",
            "Epoch 6/750\n",
            "768/768 [==============================] - 0s 426us/step - loss: 0.6306 - acc: 0.6641\n",
            "Epoch 7/750\n",
            "768/768 [==============================] - 0s 432us/step - loss: 0.6369 - acc: 0.6797\n",
            "Epoch 8/750\n",
            "768/768 [==============================] - 0s 401us/step - loss: 0.6063 - acc: 0.6888\n",
            "Epoch 9/750\n",
            "768/768 [==============================] - 0s 435us/step - loss: 0.6057 - acc: 0.6823\n",
            "Epoch 10/750\n",
            "768/768 [==============================] - 0s 417us/step - loss: 0.6143 - acc: 0.6758\n",
            "Epoch 11/750\n",
            "768/768 [==============================] - 0s 434us/step - loss: 0.6149 - acc: 0.6849\n",
            "Epoch 12/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5971 - acc: 0.6862\n",
            "Epoch 13/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.5865 - acc: 0.7083\n",
            "Epoch 14/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.5718 - acc: 0.7201\n",
            "Epoch 15/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.5781 - acc: 0.7122\n",
            "Epoch 16/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.5774 - acc: 0.7188\n",
            "Epoch 17/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.5842 - acc: 0.6888\n",
            "Epoch 18/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.5684 - acc: 0.7214\n",
            "Epoch 19/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.5710 - acc: 0.7135\n",
            "Epoch 20/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.5829 - acc: 0.6953\n",
            "Epoch 21/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.5627 - acc: 0.7201\n",
            "Epoch 22/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.5555 - acc: 0.7240\n",
            "Epoch 23/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.5596 - acc: 0.7096\n",
            "Epoch 24/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.5389 - acc: 0.7305\n",
            "Epoch 25/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.5670 - acc: 0.7227\n",
            "Epoch 26/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.5563 - acc: 0.7331\n",
            "Epoch 27/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.5384 - acc: 0.7279\n",
            "Epoch 28/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.5418 - acc: 0.7500\n",
            "Epoch 29/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.5305 - acc: 0.7396\n",
            "Epoch 30/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.5311 - acc: 0.7448\n",
            "Epoch 31/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.5486 - acc: 0.7240\n",
            "Epoch 32/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.5233 - acc: 0.7357\n",
            "Epoch 33/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.5311 - acc: 0.7500\n",
            "Epoch 34/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.5376 - acc: 0.7279\n",
            "Epoch 35/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.5411 - acc: 0.7305\n",
            "Epoch 36/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5228 - acc: 0.7435\n",
            "Epoch 37/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.5246 - acc: 0.7396\n",
            "Epoch 38/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.5143 - acc: 0.7500\n",
            "Epoch 39/750\n",
            "768/768 [==============================] - 0s 346us/step - loss: 0.5236 - acc: 0.7396\n",
            "Epoch 40/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.5228 - acc: 0.7487\n",
            "Epoch 41/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.5127 - acc: 0.7539\n",
            "Epoch 42/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.5074 - acc: 0.7474\n",
            "Epoch 43/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.5092 - acc: 0.7513\n",
            "Epoch 44/750\n",
            "768/768 [==============================] - 0s 398us/step - loss: 0.5188 - acc: 0.7279\n",
            "Epoch 45/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.5250 - acc: 0.7370\n",
            "Epoch 46/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.5166 - acc: 0.7617\n",
            "Epoch 47/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.4941 - acc: 0.7578\n",
            "Epoch 48/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.5045 - acc: 0.7526\n",
            "Epoch 49/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.5152 - acc: 0.7435\n",
            "Epoch 50/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.5130 - acc: 0.7578\n",
            "Epoch 51/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.5013 - acc: 0.7630\n",
            "Epoch 52/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.4964 - acc: 0.7643\n",
            "Epoch 53/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.5009 - acc: 0.7643\n",
            "Epoch 54/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.5043 - acc: 0.7396\n",
            "Epoch 55/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.4899 - acc: 0.7578\n",
            "Epoch 56/750\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.4980 - acc: 0.7487\n",
            "Epoch 57/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4873 - acc: 0.7630\n",
            "Epoch 58/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4872 - acc: 0.7552\n",
            "Epoch 59/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.4886 - acc: 0.7682\n",
            "Epoch 60/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.4881 - acc: 0.7643\n",
            "Epoch 61/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.4768 - acc: 0.7526\n",
            "Epoch 62/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.4935 - acc: 0.7617\n",
            "Epoch 63/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4801 - acc: 0.7747\n",
            "Epoch 64/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.4832 - acc: 0.7617\n",
            "Epoch 65/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.4735 - acc: 0.7721\n",
            "Epoch 66/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.4754 - acc: 0.7799\n",
            "Epoch 67/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4901 - acc: 0.7552\n",
            "Epoch 68/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.4685 - acc: 0.7747\n",
            "Epoch 69/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.4870 - acc: 0.7591\n",
            "Epoch 70/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.4677 - acc: 0.7773\n",
            "Epoch 71/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.4752 - acc: 0.7734\n",
            "Epoch 72/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.4696 - acc: 0.7786\n",
            "Epoch 73/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.4677 - acc: 0.7812\n",
            "Epoch 74/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.4652 - acc: 0.7747\n",
            "Epoch 75/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.4850 - acc: 0.7513\n",
            "Epoch 76/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.4633 - acc: 0.7747\n",
            "Epoch 77/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.4675 - acc: 0.7708\n",
            "Epoch 78/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.4590 - acc: 0.7865\n",
            "Epoch 79/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4628 - acc: 0.7734\n",
            "Epoch 80/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.4599 - acc: 0.7839\n",
            "Epoch 81/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.4761 - acc: 0.7760\n",
            "Epoch 82/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.4577 - acc: 0.7760\n",
            "Epoch 83/750\n",
            "768/768 [==============================] - 0s 350us/step - loss: 0.4638 - acc: 0.7760\n",
            "Epoch 84/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4571 - acc: 0.8047\n",
            "Epoch 85/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.4549 - acc: 0.7812\n",
            "Epoch 86/750\n",
            "768/768 [==============================] - 0s 350us/step - loss: 0.4701 - acc: 0.7708\n",
            "Epoch 87/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.4672 - acc: 0.7839\n",
            "Epoch 88/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.4549 - acc: 0.7734\n",
            "Epoch 89/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.4499 - acc: 0.7865\n",
            "Epoch 90/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.4443 - acc: 0.7982\n",
            "Epoch 91/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.4468 - acc: 0.7799\n",
            "Epoch 92/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.4556 - acc: 0.7891\n",
            "Epoch 93/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.4745 - acc: 0.7786\n",
            "Epoch 94/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.4388 - acc: 0.7891\n",
            "Epoch 95/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.4522 - acc: 0.7773\n",
            "Epoch 96/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.4461 - acc: 0.7943\n",
            "Epoch 97/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.4534 - acc: 0.7773\n",
            "Epoch 98/750\n",
            "768/768 [==============================] - 0s 394us/step - loss: 0.4501 - acc: 0.7865\n",
            "Epoch 99/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.4375 - acc: 0.7773\n",
            "Epoch 100/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.4473 - acc: 0.7812\n",
            "Epoch 101/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.4345 - acc: 0.8047\n",
            "Epoch 102/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.4444 - acc: 0.8073\n",
            "Epoch 103/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.4340 - acc: 0.7969\n",
            "Epoch 104/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.4380 - acc: 0.7982\n",
            "Epoch 105/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.4423 - acc: 0.7982\n",
            "Epoch 106/750\n",
            "768/768 [==============================] - 0s 402us/step - loss: 0.4393 - acc: 0.7878\n",
            "Epoch 107/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.4266 - acc: 0.7995\n",
            "Epoch 108/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.4307 - acc: 0.8034\n",
            "Epoch 109/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.4373 - acc: 0.7891\n",
            "Epoch 110/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.4215 - acc: 0.8086\n",
            "Epoch 111/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.4302 - acc: 0.8008\n",
            "Epoch 112/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.4377 - acc: 0.7812\n",
            "Epoch 113/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.4257 - acc: 0.8099\n",
            "Epoch 114/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.4402 - acc: 0.7917\n",
            "Epoch 115/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.4157 - acc: 0.8047\n",
            "Epoch 116/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.4230 - acc: 0.8112\n",
            "Epoch 117/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.4183 - acc: 0.8073\n",
            "Epoch 118/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.4284 - acc: 0.7852\n",
            "Epoch 119/750\n",
            "768/768 [==============================] - 0s 400us/step - loss: 0.4290 - acc: 0.8060\n",
            "Epoch 120/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.4225 - acc: 0.7969\n",
            "Epoch 121/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.4174 - acc: 0.8112\n",
            "Epoch 122/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.4141 - acc: 0.8138\n",
            "Epoch 123/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.4220 - acc: 0.7891\n",
            "Epoch 124/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.4149 - acc: 0.8112\n",
            "Epoch 125/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.4183 - acc: 0.7969\n",
            "Epoch 126/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.4088 - acc: 0.8125\n",
            "Epoch 127/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.4113 - acc: 0.8060\n",
            "Epoch 128/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.4081 - acc: 0.8086\n",
            "Epoch 129/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.4276 - acc: 0.8060\n",
            "Epoch 130/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.4013 - acc: 0.8099\n",
            "Epoch 131/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.4152 - acc: 0.8099\n",
            "Epoch 132/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.4153 - acc: 0.8086\n",
            "Epoch 133/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.4024 - acc: 0.8112\n",
            "Epoch 134/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.4326 - acc: 0.7982\n",
            "Epoch 135/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.4271 - acc: 0.8112\n",
            "Epoch 136/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.4063 - acc: 0.8047\n",
            "Epoch 137/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.4247 - acc: 0.7969\n",
            "Epoch 138/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.4056 - acc: 0.8047\n",
            "Epoch 139/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.4100 - acc: 0.7969\n",
            "Epoch 140/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.4387 - acc: 0.7865\n",
            "Epoch 141/750\n",
            "768/768 [==============================] - 0s 393us/step - loss: 0.4272 - acc: 0.7917\n",
            "Epoch 142/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.4104 - acc: 0.8151\n",
            "Epoch 143/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3981 - acc: 0.8229\n",
            "Epoch 144/750\n",
            "768/768 [==============================] - 0s 394us/step - loss: 0.4022 - acc: 0.8060\n",
            "Epoch 145/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.4017 - acc: 0.8281\n",
            "Epoch 146/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.4038 - acc: 0.8216\n",
            "Epoch 147/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.4067 - acc: 0.8112\n",
            "Epoch 148/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.4040 - acc: 0.8164\n",
            "Epoch 149/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.3921 - acc: 0.8190\n",
            "Epoch 150/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.3961 - acc: 0.8034\n",
            "Epoch 151/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.3952 - acc: 0.8177\n",
            "Epoch 152/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.3952 - acc: 0.8164\n",
            "Epoch 153/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3970 - acc: 0.8255\n",
            "Epoch 154/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3965 - acc: 0.8060\n",
            "Epoch 155/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.3845 - acc: 0.8216\n",
            "Epoch 156/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3856 - acc: 0.8216\n",
            "Epoch 157/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3793 - acc: 0.8164\n",
            "Epoch 158/750\n",
            "768/768 [==============================] - 0s 344us/step - loss: 0.3864 - acc: 0.8281\n",
            "Epoch 159/750\n",
            "768/768 [==============================] - 0s 397us/step - loss: 0.4021 - acc: 0.8112\n",
            "Epoch 160/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.3846 - acc: 0.8281\n",
            "Epoch 161/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.3812 - acc: 0.8268\n",
            "Epoch 162/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.4139 - acc: 0.8112\n",
            "Epoch 163/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.3834 - acc: 0.8190\n",
            "Epoch 164/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3813 - acc: 0.8268\n",
            "Epoch 165/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.3660 - acc: 0.8229\n",
            "Epoch 166/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.3868 - acc: 0.8229\n",
            "Epoch 167/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.3737 - acc: 0.8268\n",
            "Epoch 168/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.3723 - acc: 0.8216\n",
            "Epoch 169/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.3873 - acc: 0.8281\n",
            "Epoch 170/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.3892 - acc: 0.8138\n",
            "Epoch 171/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.3873 - acc: 0.8164\n",
            "Epoch 172/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.3782 - acc: 0.8320\n",
            "Epoch 173/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3905 - acc: 0.8229\n",
            "Epoch 174/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.3958 - acc: 0.8203\n",
            "Epoch 175/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.3879 - acc: 0.8034\n",
            "Epoch 176/750\n",
            "768/768 [==============================] - 0s 407us/step - loss: 0.3710 - acc: 0.8268\n",
            "Epoch 177/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3815 - acc: 0.8229\n",
            "Epoch 178/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.3773 - acc: 0.8333\n",
            "Epoch 179/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.3592 - acc: 0.8490\n",
            "Epoch 180/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3530 - acc: 0.8255\n",
            "Epoch 181/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3609 - acc: 0.8424\n",
            "Epoch 182/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.4053 - acc: 0.8099\n",
            "Epoch 183/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.3608 - acc: 0.8307\n",
            "Epoch 184/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3580 - acc: 0.8294\n",
            "Epoch 185/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.3887 - acc: 0.8151\n",
            "Epoch 186/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3666 - acc: 0.8294\n",
            "Epoch 187/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3743 - acc: 0.8255\n",
            "Epoch 188/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.3869 - acc: 0.8086\n",
            "Epoch 189/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.3593 - acc: 0.8346\n",
            "Epoch 190/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3729 - acc: 0.8242\n",
            "Epoch 191/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.3562 - acc: 0.8372\n",
            "Epoch 192/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3673 - acc: 0.8464\n",
            "Epoch 193/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3575 - acc: 0.8281\n",
            "Epoch 194/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3457 - acc: 0.8477\n",
            "Epoch 195/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.3647 - acc: 0.8464\n",
            "Epoch 196/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3738 - acc: 0.8164\n",
            "Epoch 197/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3710 - acc: 0.8268\n",
            "Epoch 198/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.3915 - acc: 0.8203\n",
            "Epoch 199/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.3576 - acc: 0.8294\n",
            "Epoch 200/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.3591 - acc: 0.8359\n",
            "Epoch 201/750\n",
            "768/768 [==============================] - 0s 400us/step - loss: 0.3673 - acc: 0.8385\n",
            "Epoch 202/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3687 - acc: 0.8385\n",
            "Epoch 203/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.3819 - acc: 0.8255\n",
            "Epoch 204/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3760 - acc: 0.8255\n",
            "Epoch 205/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3646 - acc: 0.8281\n",
            "Epoch 206/750\n",
            "768/768 [==============================] - 0s 393us/step - loss: 0.3881 - acc: 0.8359\n",
            "Epoch 207/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3852 - acc: 0.8203\n",
            "Epoch 208/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.3412 - acc: 0.8568\n",
            "Epoch 209/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.3509 - acc: 0.8581\n",
            "Epoch 210/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.3649 - acc: 0.8177\n",
            "Epoch 211/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.3534 - acc: 0.8490\n",
            "Epoch 212/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.3600 - acc: 0.8555\n",
            "Epoch 213/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.3959 - acc: 0.8060\n",
            "Epoch 214/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.3584 - acc: 0.8437\n",
            "Epoch 215/750\n",
            "768/768 [==============================] - 0s 412us/step - loss: 0.3577 - acc: 0.8464\n",
            "Epoch 216/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.3477 - acc: 0.8424\n",
            "Epoch 217/750\n",
            "768/768 [==============================] - 0s 410us/step - loss: 0.3663 - acc: 0.8320\n",
            "Epoch 218/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3616 - acc: 0.8424\n",
            "Epoch 219/750\n",
            "768/768 [==============================] - 0s 403us/step - loss: 0.3413 - acc: 0.8568\n",
            "Epoch 220/750\n",
            "768/768 [==============================] - 0s 391us/step - loss: 0.3623 - acc: 0.8411\n",
            "Epoch 221/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.3687 - acc: 0.8294\n",
            "Epoch 222/750\n",
            "768/768 [==============================] - 0s 391us/step - loss: 0.3543 - acc: 0.8294\n",
            "Epoch 223/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3500 - acc: 0.8451\n",
            "Epoch 224/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.3480 - acc: 0.8451\n",
            "Epoch 225/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.3386 - acc: 0.8477\n",
            "Epoch 226/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3363 - acc: 0.8464\n",
            "Epoch 227/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.3314 - acc: 0.8594\n",
            "Epoch 228/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.3532 - acc: 0.8594\n",
            "Epoch 229/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.3423 - acc: 0.8529\n",
            "Epoch 230/750\n",
            "768/768 [==============================] - 0s 400us/step - loss: 0.3533 - acc: 0.8307\n",
            "Epoch 231/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.3322 - acc: 0.8437\n",
            "Epoch 232/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3411 - acc: 0.8424\n",
            "Epoch 233/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.3325 - acc: 0.8490\n",
            "Epoch 234/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3566 - acc: 0.8320\n",
            "Epoch 235/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.3306 - acc: 0.8620\n",
            "Epoch 236/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.3435 - acc: 0.8464\n",
            "Epoch 237/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3358 - acc: 0.8464\n",
            "Epoch 238/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.3526 - acc: 0.8398\n",
            "Epoch 239/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.3973 - acc: 0.8255\n",
            "Epoch 240/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.3418 - acc: 0.8516\n",
            "Epoch 241/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.3412 - acc: 0.8451\n",
            "Epoch 242/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3420 - acc: 0.8398\n",
            "Epoch 243/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.3417 - acc: 0.8516\n",
            "Epoch 244/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.3496 - acc: 0.8464\n",
            "Epoch 245/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3403 - acc: 0.8490\n",
            "Epoch 246/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3447 - acc: 0.8451\n",
            "Epoch 247/750\n",
            "768/768 [==============================] - 0s 399us/step - loss: 0.3386 - acc: 0.8542\n",
            "Epoch 248/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3469 - acc: 0.8503\n",
            "Epoch 249/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.3237 - acc: 0.8555\n",
            "Epoch 250/750\n",
            "768/768 [==============================] - 0s 395us/step - loss: 0.3451 - acc: 0.8594\n",
            "Epoch 251/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.3192 - acc: 0.8411\n",
            "Epoch 252/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.3325 - acc: 0.8451\n",
            "Epoch 253/750\n",
            "768/768 [==============================] - 0s 390us/step - loss: 0.3987 - acc: 0.8164\n",
            "Epoch 254/750\n",
            "768/768 [==============================] - 0s 403us/step - loss: 0.3537 - acc: 0.8346\n",
            "Epoch 255/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.3257 - acc: 0.8633\n",
            "Epoch 256/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.3398 - acc: 0.8529\n",
            "Epoch 257/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.3269 - acc: 0.8503\n",
            "Epoch 258/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.3334 - acc: 0.8594\n",
            "Epoch 259/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3166 - acc: 0.8633\n",
            "Epoch 260/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3189 - acc: 0.8581\n",
            "Epoch 261/750\n",
            "768/768 [==============================] - 0s 396us/step - loss: 0.3200 - acc: 0.8555\n",
            "Epoch 262/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.3279 - acc: 0.8685\n",
            "Epoch 263/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3286 - acc: 0.8503\n",
            "Epoch 264/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.3244 - acc: 0.8490\n",
            "Epoch 265/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.3349 - acc: 0.8503\n",
            "Epoch 266/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3120 - acc: 0.8607\n",
            "Epoch 267/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.3553 - acc: 0.8424\n",
            "Epoch 268/750\n",
            "768/768 [==============================] - 0s 406us/step - loss: 0.3155 - acc: 0.8711\n",
            "Epoch 269/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3166 - acc: 0.8555\n",
            "Epoch 270/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.3392 - acc: 0.8424\n",
            "Epoch 271/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.3150 - acc: 0.8633\n",
            "Epoch 272/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.3184 - acc: 0.8581\n",
            "Epoch 273/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.3091 - acc: 0.8685\n",
            "Epoch 274/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3287 - acc: 0.8411\n",
            "Epoch 275/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.3542 - acc: 0.8451\n",
            "Epoch 276/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3138 - acc: 0.8633\n",
            "Epoch 277/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.3157 - acc: 0.8568\n",
            "Epoch 278/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.3140 - acc: 0.8568\n",
            "Epoch 279/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.3439 - acc: 0.8451\n",
            "Epoch 280/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.3020 - acc: 0.8594\n",
            "Epoch 281/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.3184 - acc: 0.8437\n",
            "Epoch 282/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.3281 - acc: 0.8529\n",
            "Epoch 283/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.3160 - acc: 0.8672\n",
            "Epoch 284/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.3157 - acc: 0.8633\n",
            "Epoch 285/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.3093 - acc: 0.8607\n",
            "Epoch 286/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.3207 - acc: 0.8568\n",
            "Epoch 287/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3336 - acc: 0.8503\n",
            "Epoch 288/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.3117 - acc: 0.8685\n",
            "Epoch 289/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.3318 - acc: 0.8437\n",
            "Epoch 290/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3176 - acc: 0.8555\n",
            "Epoch 291/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3083 - acc: 0.8698\n",
            "Epoch 292/750\n",
            "768/768 [==============================] - 0s 390us/step - loss: 0.2996 - acc: 0.8581\n",
            "Epoch 293/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3082 - acc: 0.8581\n",
            "Epoch 294/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.3027 - acc: 0.8633\n",
            "Epoch 295/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.3065 - acc: 0.8581\n",
            "Epoch 296/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3049 - acc: 0.8542\n",
            "Epoch 297/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.3065 - acc: 0.8763\n",
            "Epoch 298/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.3392 - acc: 0.8568\n",
            "Epoch 299/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.3146 - acc: 0.8503\n",
            "Epoch 300/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.3159 - acc: 0.8607\n",
            "Epoch 301/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2999 - acc: 0.8620\n",
            "Epoch 302/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3339 - acc: 0.8477\n",
            "Epoch 303/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.3017 - acc: 0.8633\n",
            "Epoch 304/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2861 - acc: 0.8763\n",
            "Epoch 305/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2975 - acc: 0.8698\n",
            "Epoch 306/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.3176 - acc: 0.8451\n",
            "Epoch 307/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3036 - acc: 0.8594\n",
            "Epoch 308/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2922 - acc: 0.8711\n",
            "Epoch 309/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3053 - acc: 0.8620\n",
            "Epoch 310/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.2988 - acc: 0.8711\n",
            "Epoch 311/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.3126 - acc: 0.8633\n",
            "Epoch 312/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2943 - acc: 0.8672\n",
            "Epoch 313/750\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.3026 - acc: 0.8672\n",
            "Epoch 314/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.3223 - acc: 0.8594\n",
            "Epoch 315/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2920 - acc: 0.8698\n",
            "Epoch 316/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2978 - acc: 0.8672\n",
            "Epoch 317/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3109 - acc: 0.8672\n",
            "Epoch 318/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2943 - acc: 0.8802\n",
            "Epoch 319/750\n",
            "768/768 [==============================] - 0s 400us/step - loss: 0.2858 - acc: 0.8750\n",
            "Epoch 320/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3421 - acc: 0.8503\n",
            "Epoch 321/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.4261 - acc: 0.8177\n",
            "Epoch 322/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.4107 - acc: 0.8229\n",
            "Epoch 323/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3182 - acc: 0.8646\n",
            "Epoch 324/750\n",
            "768/768 [==============================] - 0s 395us/step - loss: 0.3289 - acc: 0.8568\n",
            "Epoch 325/750\n",
            "768/768 [==============================] - 0s 406us/step - loss: 0.3256 - acc: 0.8581\n",
            "Epoch 326/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2851 - acc: 0.8594\n",
            "Epoch 327/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.2829 - acc: 0.8802\n",
            "Epoch 328/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3075 - acc: 0.8646\n",
            "Epoch 329/750\n",
            "768/768 [==============================] - 0s 338us/step - loss: 0.2920 - acc: 0.8841\n",
            "Epoch 330/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2797 - acc: 0.8750\n",
            "Epoch 331/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.3025 - acc: 0.8711\n",
            "Epoch 332/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2889 - acc: 0.8685\n",
            "Epoch 333/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2895 - acc: 0.8789\n",
            "Epoch 334/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.2930 - acc: 0.8711\n",
            "Epoch 335/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2848 - acc: 0.8776\n",
            "Epoch 336/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2830 - acc: 0.8620\n",
            "Epoch 337/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.3032 - acc: 0.8659\n",
            "Epoch 338/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2927 - acc: 0.8620\n",
            "Epoch 339/750\n",
            "768/768 [==============================] - 0s 398us/step - loss: 0.2826 - acc: 0.8802\n",
            "Epoch 340/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2744 - acc: 0.8906\n",
            "Epoch 341/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.3076 - acc: 0.8594\n",
            "Epoch 342/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.3730 - acc: 0.8398\n",
            "Epoch 343/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.3097 - acc: 0.8698\n",
            "Epoch 344/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.2836 - acc: 0.8724\n",
            "Epoch 345/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2923 - acc: 0.8698\n",
            "Epoch 346/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2968 - acc: 0.8776\n",
            "Epoch 347/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2867 - acc: 0.8711\n",
            "Epoch 348/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2884 - acc: 0.8672\n",
            "Epoch 349/750\n",
            "768/768 [==============================] - 0s 391us/step - loss: 0.2872 - acc: 0.8724\n",
            "Epoch 350/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2988 - acc: 0.8685\n",
            "Epoch 351/750\n",
            "768/768 [==============================] - 0s 348us/step - loss: 0.2999 - acc: 0.8529\n",
            "Epoch 352/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2866 - acc: 0.8685\n",
            "Epoch 353/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2806 - acc: 0.8737\n",
            "Epoch 354/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2823 - acc: 0.8815\n",
            "Epoch 355/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.3098 - acc: 0.8685\n",
            "Epoch 356/750\n",
            "768/768 [==============================] - 0s 394us/step - loss: 0.3064 - acc: 0.8646\n",
            "Epoch 357/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2856 - acc: 0.8620\n",
            "Epoch 358/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2855 - acc: 0.8789\n",
            "Epoch 359/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2910 - acc: 0.8815\n",
            "Epoch 360/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2789 - acc: 0.8776\n",
            "Epoch 361/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2759 - acc: 0.8698\n",
            "Epoch 362/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2790 - acc: 0.8737\n",
            "Epoch 363/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2701 - acc: 0.8815\n",
            "Epoch 364/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.3091 - acc: 0.8646\n",
            "Epoch 365/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2722 - acc: 0.8815\n",
            "Epoch 366/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2720 - acc: 0.8841\n",
            "Epoch 367/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.3110 - acc: 0.8568\n",
            "Epoch 368/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2820 - acc: 0.8802\n",
            "Epoch 369/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.3107 - acc: 0.8542\n",
            "Epoch 370/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2949 - acc: 0.8750\n",
            "Epoch 371/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2810 - acc: 0.8724\n",
            "Epoch 372/750\n",
            "768/768 [==============================] - 0s 350us/step - loss: 0.2922 - acc: 0.8828\n",
            "Epoch 373/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2887 - acc: 0.8659\n",
            "Epoch 374/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3512 - acc: 0.8451\n",
            "Epoch 375/750\n",
            "768/768 [==============================] - 0s 402us/step - loss: 0.3093 - acc: 0.8594\n",
            "Epoch 376/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.3022 - acc: 0.8685\n",
            "Epoch 377/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.3010 - acc: 0.8646\n",
            "Epoch 378/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.3337 - acc: 0.8529\n",
            "Epoch 379/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.4021 - acc: 0.8268\n",
            "Epoch 380/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.3059 - acc: 0.8646\n",
            "Epoch 381/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.3190 - acc: 0.8685\n",
            "Epoch 382/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3001 - acc: 0.8711\n",
            "Epoch 383/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2978 - acc: 0.8750\n",
            "Epoch 384/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2848 - acc: 0.8763\n",
            "Epoch 385/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2662 - acc: 0.8763\n",
            "Epoch 386/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.2784 - acc: 0.8867\n",
            "Epoch 387/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2679 - acc: 0.8789\n",
            "Epoch 388/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2768 - acc: 0.8854\n",
            "Epoch 389/750\n",
            "768/768 [==============================] - 0s 404us/step - loss: 0.2718 - acc: 0.8841\n",
            "Epoch 390/750\n",
            "768/768 [==============================] - 0s 400us/step - loss: 0.2732 - acc: 0.8867\n",
            "Epoch 391/750\n",
            "768/768 [==============================] - 0s 403us/step - loss: 0.2748 - acc: 0.8945\n",
            "Epoch 392/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.2579 - acc: 0.8867\n",
            "Epoch 393/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2665 - acc: 0.8867\n",
            "Epoch 394/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2936 - acc: 0.8698\n",
            "Epoch 395/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2898 - acc: 0.8698\n",
            "Epoch 396/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3036 - acc: 0.8646\n",
            "Epoch 397/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2640 - acc: 0.8802\n",
            "Epoch 398/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.2548 - acc: 0.8958\n",
            "Epoch 399/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.2885 - acc: 0.8815\n",
            "Epoch 400/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2671 - acc: 0.8828\n",
            "Epoch 401/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3424 - acc: 0.8451\n",
            "Epoch 402/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.3227 - acc: 0.8581\n",
            "Epoch 403/750\n",
            "768/768 [==============================] - 0s 406us/step - loss: 0.2844 - acc: 0.8737\n",
            "Epoch 404/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2663 - acc: 0.8828\n",
            "Epoch 405/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2665 - acc: 0.8841\n",
            "Epoch 406/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.2731 - acc: 0.8789\n",
            "Epoch 407/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2568 - acc: 0.8997\n",
            "Epoch 408/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2571 - acc: 0.8997\n",
            "Epoch 409/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2548 - acc: 0.8880\n",
            "Epoch 410/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2761 - acc: 0.8815\n",
            "Epoch 411/750\n",
            "768/768 [==============================] - 0s 393us/step - loss: 0.2679 - acc: 0.8828\n",
            "Epoch 412/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2802 - acc: 0.8802\n",
            "Epoch 413/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2632 - acc: 0.8880\n",
            "Epoch 414/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2667 - acc: 0.8737\n",
            "Epoch 415/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2724 - acc: 0.8854\n",
            "Epoch 416/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2573 - acc: 0.8919\n",
            "Epoch 417/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3018 - acc: 0.8568\n",
            "Epoch 418/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2879 - acc: 0.8685\n",
            "Epoch 419/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2855 - acc: 0.8828\n",
            "Epoch 420/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.3144 - acc: 0.8776\n",
            "Epoch 421/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3084 - acc: 0.8776\n",
            "Epoch 422/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3051 - acc: 0.8568\n",
            "Epoch 423/750\n",
            "768/768 [==============================] - 0s 395us/step - loss: 0.2892 - acc: 0.8750\n",
            "Epoch 424/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3336 - acc: 0.8437\n",
            "Epoch 425/750\n",
            "768/768 [==============================] - 0s 347us/step - loss: 0.2969 - acc: 0.8776\n",
            "Epoch 426/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2641 - acc: 0.8802\n",
            "Epoch 427/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3291 - acc: 0.8763\n",
            "Epoch 428/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2837 - acc: 0.8815\n",
            "Epoch 429/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2560 - acc: 0.8763\n",
            "Epoch 430/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.2560 - acc: 0.8880\n",
            "Epoch 431/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2596 - acc: 0.8841\n",
            "Epoch 432/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2558 - acc: 0.8802\n",
            "Epoch 433/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2480 - acc: 0.8919\n",
            "Epoch 434/750\n",
            "768/768 [==============================] - 0s 347us/step - loss: 0.2503 - acc: 0.8854\n",
            "Epoch 435/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2882 - acc: 0.8659\n",
            "Epoch 436/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2603 - acc: 0.8789\n",
            "Epoch 437/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2849 - acc: 0.8763\n",
            "Epoch 438/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2580 - acc: 0.8802\n",
            "Epoch 439/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2559 - acc: 0.8867\n",
            "Epoch 440/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2819 - acc: 0.8698\n",
            "Epoch 441/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2675 - acc: 0.8763\n",
            "Epoch 442/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2798 - acc: 0.8724\n",
            "Epoch 443/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2510 - acc: 0.8854\n",
            "Epoch 444/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2635 - acc: 0.8776\n",
            "Epoch 445/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2565 - acc: 0.8828\n",
            "Epoch 446/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2733 - acc: 0.8659\n",
            "Epoch 447/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2555 - acc: 0.8867\n",
            "Epoch 448/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2726 - acc: 0.8659\n",
            "Epoch 449/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2523 - acc: 0.8867\n",
            "Epoch 450/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.2539 - acc: 0.8893\n",
            "Epoch 451/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2717 - acc: 0.8815\n",
            "Epoch 452/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2522 - acc: 0.8893\n",
            "Epoch 453/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2413 - acc: 0.8945\n",
            "Epoch 454/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2577 - acc: 0.8867\n",
            "Epoch 455/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2409 - acc: 0.8919\n",
            "Epoch 456/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2380 - acc: 0.8828\n",
            "Epoch 457/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2760 - acc: 0.8646\n",
            "Epoch 458/750\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.2745 - acc: 0.8698\n",
            "Epoch 459/750\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.2523 - acc: 0.8867\n",
            "Epoch 460/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2355 - acc: 0.8984\n",
            "Epoch 461/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.2432 - acc: 0.8932\n",
            "Epoch 462/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2484 - acc: 0.8854\n",
            "Epoch 463/750\n",
            "768/768 [==============================] - 0s 349us/step - loss: 0.2827 - acc: 0.8802\n",
            "Epoch 464/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2544 - acc: 0.8867\n",
            "Epoch 465/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2857 - acc: 0.8711\n",
            "Epoch 466/750\n",
            "768/768 [==============================] - 0s 349us/step - loss: 0.2805 - acc: 0.8659\n",
            "Epoch 467/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.2740 - acc: 0.8802\n",
            "Epoch 468/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2408 - acc: 0.8893\n",
            "Epoch 469/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2520 - acc: 0.8919\n",
            "Epoch 470/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2530 - acc: 0.8880\n",
            "Epoch 471/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.2378 - acc: 0.8919\n",
            "Epoch 472/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2540 - acc: 0.8880\n",
            "Epoch 473/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.2550 - acc: 0.8867\n",
            "Epoch 474/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2751 - acc: 0.8750\n",
            "Epoch 475/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.2360 - acc: 0.8971\n",
            "Epoch 476/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2723 - acc: 0.8776\n",
            "Epoch 477/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2662 - acc: 0.8763\n",
            "Epoch 478/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.2353 - acc: 0.8984\n",
            "Epoch 479/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2557 - acc: 0.8828\n",
            "Epoch 480/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2776 - acc: 0.8763\n",
            "Epoch 481/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2623 - acc: 0.8932\n",
            "Epoch 482/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2536 - acc: 0.8893\n",
            "Epoch 483/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2570 - acc: 0.8854\n",
            "Epoch 484/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2416 - acc: 0.8984\n",
            "Epoch 485/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2460 - acc: 0.8867\n",
            "Epoch 486/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.2280 - acc: 0.9036\n",
            "Epoch 487/750\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.3400 - acc: 0.8516\n",
            "Epoch 488/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.3088 - acc: 0.8711\n",
            "Epoch 489/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.2475 - acc: 0.8997\n",
            "Epoch 490/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2330 - acc: 0.9010\n",
            "Epoch 491/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.2484 - acc: 0.8945\n",
            "Epoch 492/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.2311 - acc: 0.9049\n",
            "Epoch 493/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2852 - acc: 0.8763\n",
            "Epoch 494/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.3455 - acc: 0.8529\n",
            "Epoch 495/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3107 - acc: 0.8568\n",
            "Epoch 496/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2798 - acc: 0.8841\n",
            "Epoch 497/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2446 - acc: 0.8906\n",
            "Epoch 498/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2659 - acc: 0.8802\n",
            "Epoch 499/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2616 - acc: 0.8802\n",
            "Epoch 500/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.2355 - acc: 0.8958\n",
            "Epoch 501/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2364 - acc: 0.8997\n",
            "Epoch 502/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2308 - acc: 0.9062\n",
            "Epoch 503/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2558 - acc: 0.8906\n",
            "Epoch 504/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.2346 - acc: 0.8906\n",
            "Epoch 505/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2369 - acc: 0.9023\n",
            "Epoch 506/750\n",
            "768/768 [==============================] - 0s 399us/step - loss: 0.2497 - acc: 0.8867\n",
            "Epoch 507/750\n",
            "768/768 [==============================] - 0s 401us/step - loss: 0.3409 - acc: 0.8646\n",
            "Epoch 508/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2833 - acc: 0.8685\n",
            "Epoch 509/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.2317 - acc: 0.8958\n",
            "Epoch 510/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2457 - acc: 0.8984\n",
            "Epoch 511/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.2248 - acc: 0.9023\n",
            "Epoch 512/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2243 - acc: 0.9049\n",
            "Epoch 513/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2641 - acc: 0.8854\n",
            "Epoch 514/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.2421 - acc: 0.8919\n",
            "Epoch 515/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2490 - acc: 0.8750\n",
            "Epoch 516/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2328 - acc: 0.8932\n",
            "Epoch 517/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.2462 - acc: 0.8919\n",
            "Epoch 518/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.2697 - acc: 0.8841\n",
            "Epoch 519/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.2701 - acc: 0.8724\n",
            "Epoch 520/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2334 - acc: 0.8945\n",
            "Epoch 521/750\n",
            "768/768 [==============================] - 0s 399us/step - loss: 0.2641 - acc: 0.8750\n",
            "Epoch 522/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2411 - acc: 0.8867\n",
            "Epoch 523/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.2399 - acc: 0.8984\n",
            "Epoch 524/750\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.2481 - acc: 0.8828\n",
            "Epoch 525/750\n",
            "768/768 [==============================] - 0s 390us/step - loss: 0.2615 - acc: 0.8763\n",
            "Epoch 526/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2588 - acc: 0.8854\n",
            "Epoch 527/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2468 - acc: 0.8945\n",
            "Epoch 528/750\n",
            "768/768 [==============================] - 0s 398us/step - loss: 0.2448 - acc: 0.8906\n",
            "Epoch 529/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.2915 - acc: 0.8672\n",
            "Epoch 530/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.2334 - acc: 0.8932\n",
            "Epoch 531/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.2254 - acc: 0.9062\n",
            "Epoch 532/750\n",
            "768/768 [==============================] - 0s 411us/step - loss: 0.2232 - acc: 0.8932\n",
            "Epoch 533/750\n",
            "768/768 [==============================] - 0s 394us/step - loss: 0.2410 - acc: 0.8932\n",
            "Epoch 534/750\n",
            "768/768 [==============================] - 0s 396us/step - loss: 0.2847 - acc: 0.8698\n",
            "Epoch 535/750\n",
            "768/768 [==============================] - 0s 393us/step - loss: 0.3033 - acc: 0.8698\n",
            "Epoch 536/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2782 - acc: 0.8763\n",
            "Epoch 537/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2588 - acc: 0.8906\n",
            "Epoch 538/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2798 - acc: 0.8737\n",
            "Epoch 539/750\n",
            "768/768 [==============================] - 0s 398us/step - loss: 0.2428 - acc: 0.8893\n",
            "Epoch 540/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2363 - acc: 0.8880\n",
            "Epoch 541/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2526 - acc: 0.8841\n",
            "Epoch 542/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.2529 - acc: 0.8828\n",
            "Epoch 543/750\n",
            "768/768 [==============================] - 0s 405us/step - loss: 0.2506 - acc: 0.8867\n",
            "Epoch 544/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2577 - acc: 0.8763\n",
            "Epoch 545/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.3126 - acc: 0.8581\n",
            "Epoch 546/750\n",
            "768/768 [==============================] - 0s 405us/step - loss: 0.2603 - acc: 0.8854\n",
            "Epoch 547/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2569 - acc: 0.8867\n",
            "Epoch 548/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2310 - acc: 0.8945\n",
            "Epoch 549/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2653 - acc: 0.8789\n",
            "Epoch 550/750\n",
            "768/768 [==============================] - 0s 391us/step - loss: 0.2696 - acc: 0.8737\n",
            "Epoch 551/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.2452 - acc: 0.8828\n",
            "Epoch 552/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2408 - acc: 0.8945\n",
            "Epoch 553/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2247 - acc: 0.8997\n",
            "Epoch 554/750\n",
            "768/768 [==============================] - 0s 350us/step - loss: 0.2613 - acc: 0.8776\n",
            "Epoch 555/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2592 - acc: 0.8802\n",
            "Epoch 556/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2455 - acc: 0.8841\n",
            "Epoch 557/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2344 - acc: 0.9023\n",
            "Epoch 558/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2404 - acc: 0.8932\n",
            "Epoch 559/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2469 - acc: 0.8841\n",
            "Epoch 560/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.2474 - acc: 0.8919\n",
            "Epoch 561/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2905 - acc: 0.8763\n",
            "Epoch 562/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.2587 - acc: 0.8789\n",
            "Epoch 563/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2593 - acc: 0.8841\n",
            "Epoch 564/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.2366 - acc: 0.8997\n",
            "Epoch 565/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2443 - acc: 0.8880\n",
            "Epoch 566/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2240 - acc: 0.8958\n",
            "Epoch 567/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2462 - acc: 0.8802\n",
            "Epoch 568/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2256 - acc: 0.8971\n",
            "Epoch 569/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2328 - acc: 0.8880\n",
            "Epoch 570/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2382 - acc: 0.9062\n",
            "Epoch 571/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2217 - acc: 0.8932\n",
            "Epoch 572/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2633 - acc: 0.8776\n",
            "Epoch 573/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2418 - acc: 0.8841\n",
            "Epoch 574/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2436 - acc: 0.8815\n",
            "Epoch 575/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2605 - acc: 0.8854\n",
            "Epoch 576/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2323 - acc: 0.8906\n",
            "Epoch 577/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2268 - acc: 0.9010\n",
            "Epoch 578/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2503 - acc: 0.8893\n",
            "Epoch 579/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2289 - acc: 0.8932\n",
            "Epoch 580/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2344 - acc: 0.8893\n",
            "Epoch 581/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2294 - acc: 0.8906\n",
            "Epoch 582/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2175 - acc: 0.9062\n",
            "Epoch 583/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2261 - acc: 0.8984\n",
            "Epoch 584/750\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.2201 - acc: 0.8971\n",
            "Epoch 585/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2225 - acc: 0.8919\n",
            "Epoch 586/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2426 - acc: 0.8828\n",
            "Epoch 587/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2273 - acc: 0.8893\n",
            "Epoch 588/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2824 - acc: 0.8815\n",
            "Epoch 589/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2902 - acc: 0.8776\n",
            "Epoch 590/750\n",
            "768/768 [==============================] - 0s 350us/step - loss: 0.3126 - acc: 0.8620\n",
            "Epoch 591/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2671 - acc: 0.8906\n",
            "Epoch 592/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2835 - acc: 0.8789\n",
            "Epoch 593/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.2364 - acc: 0.8984\n",
            "Epoch 594/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2513 - acc: 0.8919\n",
            "Epoch 595/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.3435 - acc: 0.8529\n",
            "Epoch 596/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2807 - acc: 0.8724\n",
            "Epoch 597/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2402 - acc: 0.8919\n",
            "Epoch 598/750\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.2482 - acc: 0.8997\n",
            "Epoch 599/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2362 - acc: 0.9049\n",
            "Epoch 600/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2526 - acc: 0.8880\n",
            "Epoch 601/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2475 - acc: 0.8984\n",
            "Epoch 602/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2632 - acc: 0.8867\n",
            "Epoch 603/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2480 - acc: 0.9049\n",
            "Epoch 604/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2754 - acc: 0.8867\n",
            "Epoch 605/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.2337 - acc: 0.9102\n",
            "Epoch 606/750\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.2421 - acc: 0.8919\n",
            "Epoch 607/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2795 - acc: 0.8854\n",
            "Epoch 608/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2425 - acc: 0.9036\n",
            "Epoch 609/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2213 - acc: 0.8958\n",
            "Epoch 610/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2257 - acc: 0.8919\n",
            "Epoch 611/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2508 - acc: 0.8841\n",
            "Epoch 612/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.2268 - acc: 0.8932\n",
            "Epoch 613/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2471 - acc: 0.8971\n",
            "Epoch 614/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2480 - acc: 0.9036\n",
            "Epoch 615/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2277 - acc: 0.8893\n",
            "Epoch 616/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2321 - acc: 0.8906\n",
            "Epoch 617/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2377 - acc: 0.9010\n",
            "Epoch 618/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.2342 - acc: 0.8958\n",
            "Epoch 619/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2276 - acc: 0.8971\n",
            "Epoch 620/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.1962 - acc: 0.9167\n",
            "Epoch 621/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2145 - acc: 0.9036\n",
            "Epoch 622/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2723 - acc: 0.8802\n",
            "Epoch 623/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2676 - acc: 0.8867\n",
            "Epoch 624/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2243 - acc: 0.9036\n",
            "Epoch 625/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2188 - acc: 0.8919\n",
            "Epoch 626/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2158 - acc: 0.9010\n",
            "Epoch 627/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2252 - acc: 0.9036\n",
            "Epoch 628/750\n",
            "768/768 [==============================] - 0s 391us/step - loss: 0.2333 - acc: 0.8958\n",
            "Epoch 629/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2060 - acc: 0.9089\n",
            "Epoch 630/750\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.2091 - acc: 0.9036\n",
            "Epoch 631/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2013 - acc: 0.9115\n",
            "Epoch 632/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.3090 - acc: 0.8789\n",
            "Epoch 633/750\n",
            "768/768 [==============================] - 0s 402us/step - loss: 0.2366 - acc: 0.9049\n",
            "Epoch 634/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2179 - acc: 0.9010\n",
            "Epoch 635/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.3063 - acc: 0.8802\n",
            "Epoch 636/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2725 - acc: 0.8802\n",
            "Epoch 637/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2707 - acc: 0.8867\n",
            "Epoch 638/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2499 - acc: 0.8802\n",
            "Epoch 639/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2317 - acc: 0.8997\n",
            "Epoch 640/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2092 - acc: 0.8997\n",
            "Epoch 641/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2082 - acc: 0.9062\n",
            "Epoch 642/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2131 - acc: 0.8945\n",
            "Epoch 643/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2008 - acc: 0.9154\n",
            "Epoch 644/750\n",
            "768/768 [==============================] - 0s 393us/step - loss: 0.2264 - acc: 0.8997\n",
            "Epoch 645/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2068 - acc: 0.9049\n",
            "Epoch 646/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.3852 - acc: 0.8437\n",
            "Epoch 647/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.3518 - acc: 0.8529\n",
            "Epoch 648/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.3131 - acc: 0.8555\n",
            "Epoch 649/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2899 - acc: 0.8646\n",
            "Epoch 650/750\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.2813 - acc: 0.8776\n",
            "Epoch 651/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.3501 - acc: 0.8516\n",
            "Epoch 652/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2630 - acc: 0.8854\n",
            "Epoch 653/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2675 - acc: 0.8789\n",
            "Epoch 654/750\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.3161 - acc: 0.8529\n",
            "Epoch 655/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2651 - acc: 0.8841\n",
            "Epoch 656/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2786 - acc: 0.8698\n",
            "Epoch 657/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.2625 - acc: 0.8932\n",
            "Epoch 658/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2209 - acc: 0.9023\n",
            "Epoch 659/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2259 - acc: 0.8932\n",
            "Epoch 660/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2263 - acc: 0.9010\n",
            "Epoch 661/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2687 - acc: 0.8698\n",
            "Epoch 662/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2187 - acc: 0.9089\n",
            "Epoch 663/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.2047 - acc: 0.9036\n",
            "Epoch 664/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.2228 - acc: 0.8997\n",
            "Epoch 665/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2139 - acc: 0.9102\n",
            "Epoch 666/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2166 - acc: 0.8919\n",
            "Epoch 667/750\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.2182 - acc: 0.9023\n",
            "Epoch 668/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2145 - acc: 0.8932\n",
            "Epoch 669/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.1991 - acc: 0.9089\n",
            "Epoch 670/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2119 - acc: 0.9023\n",
            "Epoch 671/750\n",
            "768/768 [==============================] - 0s 382us/step - loss: 0.2170 - acc: 0.9102\n",
            "Epoch 672/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2057 - acc: 0.9128\n",
            "Epoch 673/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.1931 - acc: 0.9245\n",
            "Epoch 674/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2084 - acc: 0.9062\n",
            "Epoch 675/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2490 - acc: 0.8880\n",
            "Epoch 676/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.2467 - acc: 0.8867\n",
            "Epoch 677/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2163 - acc: 0.9010\n",
            "Epoch 678/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.2120 - acc: 0.9062\n",
            "Epoch 679/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.2133 - acc: 0.9076\n",
            "Epoch 680/750\n",
            "768/768 [==============================] - 0s 348us/step - loss: 0.2124 - acc: 0.9180\n",
            "Epoch 681/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2313 - acc: 0.9023\n",
            "Epoch 682/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.2064 - acc: 0.9115\n",
            "Epoch 683/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2085 - acc: 0.9010\n",
            "Epoch 684/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2012 - acc: 0.9141\n",
            "Epoch 685/750\n",
            "768/768 [==============================] - 0s 398us/step - loss: 0.2089 - acc: 0.8971\n",
            "Epoch 686/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2088 - acc: 0.8997\n",
            "Epoch 687/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2406 - acc: 0.8958\n",
            "Epoch 688/750\n",
            "768/768 [==============================] - 0s 344us/step - loss: 0.3046 - acc: 0.8711\n",
            "Epoch 689/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.3619 - acc: 0.8490\n",
            "Epoch 690/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2887 - acc: 0.8802\n",
            "Epoch 691/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2479 - acc: 0.8893\n",
            "Epoch 692/750\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.2068 - acc: 0.9102\n",
            "Epoch 693/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2108 - acc: 0.9089\n",
            "Epoch 694/750\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.2018 - acc: 0.9102\n",
            "Epoch 695/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.1968 - acc: 0.9089\n",
            "Epoch 696/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.1978 - acc: 0.9141\n",
            "Epoch 697/750\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.2604 - acc: 0.8867\n",
            "Epoch 698/750\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.2248 - acc: 0.9010\n",
            "Epoch 699/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2502 - acc: 0.8984\n",
            "Epoch 700/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2077 - acc: 0.9010\n",
            "Epoch 701/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.2046 - acc: 0.9115\n",
            "Epoch 702/750\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.2022 - acc: 0.8958\n",
            "Epoch 703/750\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.2209 - acc: 0.9089\n",
            "Epoch 704/750\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.2524 - acc: 0.8789\n",
            "Epoch 705/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2902 - acc: 0.8789\n",
            "Epoch 706/750\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.2324 - acc: 0.8854\n",
            "Epoch 707/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2107 - acc: 0.8997\n",
            "Epoch 708/750\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.2121 - acc: 0.9010\n",
            "Epoch 709/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2385 - acc: 0.9023\n",
            "Epoch 710/750\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.2240 - acc: 0.9076\n",
            "Epoch 711/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.2066 - acc: 0.9036\n",
            "Epoch 712/750\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.1912 - acc: 0.9102\n",
            "Epoch 713/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.2218 - acc: 0.9023\n",
            "Epoch 714/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2142 - acc: 0.8919\n",
            "Epoch 715/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.1981 - acc: 0.9036\n",
            "Epoch 716/750\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.2392 - acc: 0.8958\n",
            "Epoch 717/750\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.2700 - acc: 0.8906\n",
            "Epoch 718/750\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.2352 - acc: 0.8906\n",
            "Epoch 719/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.2492 - acc: 0.8971\n",
            "Epoch 720/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2371 - acc: 0.8906\n",
            "Epoch 721/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2041 - acc: 0.9062\n",
            "Epoch 722/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2147 - acc: 0.9023\n",
            "Epoch 723/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2113 - acc: 0.9089\n",
            "Epoch 724/750\n",
            "768/768 [==============================] - 0s 373us/step - loss: 0.2245 - acc: 0.9049\n",
            "Epoch 725/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2039 - acc: 0.9115\n",
            "Epoch 726/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.2212 - acc: 0.9049\n",
            "Epoch 727/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.1977 - acc: 0.9141\n",
            "Epoch 728/750\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.2048 - acc: 0.9115\n",
            "Epoch 729/750\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.1905 - acc: 0.9128\n",
            "Epoch 730/750\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.1923 - acc: 0.9193\n",
            "Epoch 731/750\n",
            "768/768 [==============================] - 0s 396us/step - loss: 0.2081 - acc: 0.9141\n",
            "Epoch 732/750\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.1930 - acc: 0.9049\n",
            "Epoch 733/750\n",
            "768/768 [==============================] - 0s 381us/step - loss: 0.2373 - acc: 0.8867\n",
            "Epoch 734/750\n",
            "768/768 [==============================] - 0s 368us/step - loss: 0.2381 - acc: 0.8958\n",
            "Epoch 735/750\n",
            "768/768 [==============================] - 0s 399us/step - loss: 0.2501 - acc: 0.8997\n",
            "Epoch 736/750\n",
            "768/768 [==============================] - 0s 394us/step - loss: 0.2027 - acc: 0.8997\n",
            "Epoch 737/750\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.1881 - acc: 0.9206\n",
            "Epoch 738/750\n",
            "768/768 [==============================] - 0s 407us/step - loss: 0.2020 - acc: 0.9206\n",
            "Epoch 739/750\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.2140 - acc: 0.9036\n",
            "Epoch 740/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.1834 - acc: 0.9180\n",
            "Epoch 741/750\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.1798 - acc: 0.9193\n",
            "Epoch 742/750\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.1983 - acc: 0.9076\n",
            "Epoch 743/750\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.1861 - acc: 0.9258\n",
            "Epoch 744/750\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.2136 - acc: 0.8997\n",
            "Epoch 745/750\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.2168 - acc: 0.9062\n",
            "Epoch 746/750\n",
            "768/768 [==============================] - 0s 392us/step - loss: 0.1930 - acc: 0.9062\n",
            "Epoch 747/750\n",
            "768/768 [==============================] - 0s 345us/step - loss: 0.1930 - acc: 0.9141\n",
            "Epoch 748/750\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.2070 - acc: 0.9010\n",
            "Epoch 749/750\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.2931 - acc: 0.8659\n",
            "Epoch 750/750\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.2571 - acc: 0.8997\n",
            "768/768 [==============================] - 0s 95us/step\n",
            "Accuracy: 89.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO4MGHpHQcSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "063cd363-7f9b-4d8f-b554-2607ab374171"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwdi0VpPOwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7addc442-670c-4156-c0ca-b878c1b76e1f"
      },
      "source": [
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load the dataset\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=8, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "history = model.fit(X, y,validation_split=0.33, epochs=400, batch_size=10)#model.fit(X, y, , epochs=750, batch_size=10, verbose=0)\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 514 samples, validate on 254 samples\n",
            "Epoch 1/400\n",
            "514/514 [==============================] - 1s 2ms/step - loss: 2.4830 - acc: 0.6401 - val_loss: 0.7861 - val_acc: 0.6693\n",
            "Epoch 2/400\n",
            "514/514 [==============================] - 0s 431us/step - loss: 0.7215 - acc: 0.6187 - val_loss: 0.6843 - val_acc: 0.6457\n",
            "Epoch 3/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.6764 - acc: 0.6362 - val_loss: 0.6713 - val_acc: 0.6181\n",
            "Epoch 4/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.6578 - acc: 0.6323 - val_loss: 0.6633 - val_acc: 0.6260\n",
            "Epoch 5/400\n",
            "514/514 [==============================] - 0s 426us/step - loss: 0.6569 - acc: 0.6284 - val_loss: 0.6614 - val_acc: 0.6378\n",
            "Epoch 6/400\n",
            "514/514 [==============================] - 0s 487us/step - loss: 0.6447 - acc: 0.6362 - val_loss: 0.6560 - val_acc: 0.6220\n",
            "Epoch 7/400\n",
            "514/514 [==============================] - 0s 471us/step - loss: 0.6346 - acc: 0.6401 - val_loss: 0.6603 - val_acc: 0.6181\n",
            "Epoch 8/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.6389 - acc: 0.6479 - val_loss: 0.6502 - val_acc: 0.6220\n",
            "Epoch 9/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.6290 - acc: 0.6479 - val_loss: 0.6516 - val_acc: 0.6378\n",
            "Epoch 10/400\n",
            "514/514 [==============================] - 0s 462us/step - loss: 0.6239 - acc: 0.6440 - val_loss: 0.6504 - val_acc: 0.6220\n",
            "Epoch 11/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.6155 - acc: 0.6848 - val_loss: 0.6575 - val_acc: 0.6142\n",
            "Epoch 12/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.6199 - acc: 0.6537 - val_loss: 0.6505 - val_acc: 0.6220\n",
            "Epoch 13/400\n",
            "514/514 [==============================] - 0s 469us/step - loss: 0.6158 - acc: 0.6654 - val_loss: 0.6450 - val_acc: 0.6220\n",
            "Epoch 14/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.6083 - acc: 0.6712 - val_loss: 0.6410 - val_acc: 0.6378\n",
            "Epoch 15/400\n",
            "514/514 [==============================] - 0s 467us/step - loss: 0.6097 - acc: 0.6732 - val_loss: 0.6386 - val_acc: 0.6457\n",
            "Epoch 16/400\n",
            "514/514 [==============================] - 0s 487us/step - loss: 0.6038 - acc: 0.6751 - val_loss: 0.6339 - val_acc: 0.6378\n",
            "Epoch 17/400\n",
            "514/514 [==============================] - 0s 461us/step - loss: 0.5943 - acc: 0.6946 - val_loss: 0.6288 - val_acc: 0.6575\n",
            "Epoch 18/400\n",
            "514/514 [==============================] - 0s 434us/step - loss: 0.6003 - acc: 0.6907 - val_loss: 0.6363 - val_acc: 0.6378\n",
            "Epoch 19/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.5931 - acc: 0.6848 - val_loss: 0.6294 - val_acc: 0.6378\n",
            "Epoch 20/400\n",
            "514/514 [==============================] - 0s 477us/step - loss: 0.5926 - acc: 0.6887 - val_loss: 0.6313 - val_acc: 0.6496\n",
            "Epoch 21/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.5881 - acc: 0.6965 - val_loss: 0.6240 - val_acc: 0.6535\n",
            "Epoch 22/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.5829 - acc: 0.6848 - val_loss: 0.6274 - val_acc: 0.6457\n",
            "Epoch 23/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.5812 - acc: 0.6848 - val_loss: 0.6307 - val_acc: 0.6417\n",
            "Epoch 24/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.5822 - acc: 0.6887 - val_loss: 0.6310 - val_acc: 0.6378\n",
            "Epoch 25/400\n",
            "514/514 [==============================] - 0s 475us/step - loss: 0.5730 - acc: 0.6926 - val_loss: 0.6450 - val_acc: 0.6732\n",
            "Epoch 26/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.5877 - acc: 0.6868 - val_loss: 0.6185 - val_acc: 0.6417\n",
            "Epoch 27/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.5816 - acc: 0.7062 - val_loss: 0.6122 - val_acc: 0.6575\n",
            "Epoch 28/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.5739 - acc: 0.6907 - val_loss: 0.6065 - val_acc: 0.6535\n",
            "Epoch 29/400\n",
            "514/514 [==============================] - 0s 466us/step - loss: 0.5624 - acc: 0.7101 - val_loss: 0.6097 - val_acc: 0.6732\n",
            "Epoch 30/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.5695 - acc: 0.7023 - val_loss: 0.6302 - val_acc: 0.6457\n",
            "Epoch 31/400\n",
            "514/514 [==============================] - 0s 427us/step - loss: 0.5644 - acc: 0.7179 - val_loss: 0.6188 - val_acc: 0.6575\n",
            "Epoch 32/400\n",
            "514/514 [==============================] - 0s 434us/step - loss: 0.5743 - acc: 0.7082 - val_loss: 0.6010 - val_acc: 0.6654\n",
            "Epoch 33/400\n",
            "514/514 [==============================] - 0s 450us/step - loss: 0.5619 - acc: 0.7101 - val_loss: 0.5997 - val_acc: 0.6339\n",
            "Epoch 34/400\n",
            "514/514 [==============================] - 0s 485us/step - loss: 0.5524 - acc: 0.7179 - val_loss: 0.6002 - val_acc: 0.6654\n",
            "Epoch 35/400\n",
            "514/514 [==============================] - 0s 427us/step - loss: 0.5571 - acc: 0.7160 - val_loss: 0.5894 - val_acc: 0.6850\n",
            "Epoch 36/400\n",
            "514/514 [==============================] - 0s 428us/step - loss: 0.5436 - acc: 0.7218 - val_loss: 0.6082 - val_acc: 0.6811\n",
            "Epoch 37/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.5501 - acc: 0.7082 - val_loss: 0.6077 - val_acc: 0.6575\n",
            "Epoch 38/400\n",
            "514/514 [==============================] - 0s 481us/step - loss: 0.5496 - acc: 0.7023 - val_loss: 0.6343 - val_acc: 0.6732\n",
            "Epoch 39/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.5645 - acc: 0.7004 - val_loss: 0.5896 - val_acc: 0.6496\n",
            "Epoch 40/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.5431 - acc: 0.7101 - val_loss: 0.5940 - val_acc: 0.6614\n",
            "Epoch 41/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.5454 - acc: 0.7237 - val_loss: 0.5904 - val_acc: 0.6693\n",
            "Epoch 42/400\n",
            "514/514 [==============================] - 0s 494us/step - loss: 0.5491 - acc: 0.6984 - val_loss: 0.5867 - val_acc: 0.6535\n",
            "Epoch 43/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.5371 - acc: 0.7257 - val_loss: 0.5592 - val_acc: 0.7165\n",
            "Epoch 44/400\n",
            "514/514 [==============================] - 0s 418us/step - loss: 0.5384 - acc: 0.7257 - val_loss: 0.5676 - val_acc: 0.7205\n",
            "Epoch 45/400\n",
            "514/514 [==============================] - 0s 472us/step - loss: 0.5445 - acc: 0.7082 - val_loss: 0.5661 - val_acc: 0.7126\n",
            "Epoch 46/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.5399 - acc: 0.7257 - val_loss: 0.5749 - val_acc: 0.7126\n",
            "Epoch 47/400\n",
            "514/514 [==============================] - 0s 469us/step - loss: 0.5392 - acc: 0.7296 - val_loss: 0.5681 - val_acc: 0.7087\n",
            "Epoch 48/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.5433 - acc: 0.7296 - val_loss: 0.5626 - val_acc: 0.6929\n",
            "Epoch 49/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.5515 - acc: 0.7198 - val_loss: 0.5714 - val_acc: 0.7087\n",
            "Epoch 50/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.5336 - acc: 0.7276 - val_loss: 0.5583 - val_acc: 0.7205\n",
            "Epoch 51/400\n",
            "514/514 [==============================] - 0s 478us/step - loss: 0.5307 - acc: 0.7374 - val_loss: 0.5695 - val_acc: 0.7126\n",
            "Epoch 52/400\n",
            "514/514 [==============================] - 0s 475us/step - loss: 0.5384 - acc: 0.7198 - val_loss: 0.5642 - val_acc: 0.7165\n",
            "Epoch 53/400\n",
            "514/514 [==============================] - 0s 473us/step - loss: 0.5194 - acc: 0.7276 - val_loss: 0.5558 - val_acc: 0.7283\n",
            "Epoch 54/400\n",
            "514/514 [==============================] - 0s 469us/step - loss: 0.5280 - acc: 0.7296 - val_loss: 0.5571 - val_acc: 0.7126\n",
            "Epoch 55/400\n",
            "514/514 [==============================] - 0s 497us/step - loss: 0.5317 - acc: 0.7296 - val_loss: 0.5705 - val_acc: 0.7087\n",
            "Epoch 56/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.5193 - acc: 0.7393 - val_loss: 0.5880 - val_acc: 0.6890\n",
            "Epoch 57/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.5224 - acc: 0.7412 - val_loss: 0.5518 - val_acc: 0.7205\n",
            "Epoch 58/400\n",
            "514/514 [==============================] - 0s 477us/step - loss: 0.5155 - acc: 0.7315 - val_loss: 0.5524 - val_acc: 0.7047\n",
            "Epoch 59/400\n",
            "514/514 [==============================] - 0s 489us/step - loss: 0.5179 - acc: 0.7451 - val_loss: 0.5605 - val_acc: 0.7244\n",
            "Epoch 60/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.5119 - acc: 0.7568 - val_loss: 0.5474 - val_acc: 0.7441\n",
            "Epoch 61/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.5187 - acc: 0.7374 - val_loss: 0.5603 - val_acc: 0.7362\n",
            "Epoch 62/400\n",
            "514/514 [==============================] - 0s 418us/step - loss: 0.5134 - acc: 0.7296 - val_loss: 0.5681 - val_acc: 0.7323\n",
            "Epoch 63/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.5128 - acc: 0.7315 - val_loss: 0.5482 - val_acc: 0.7402\n",
            "Epoch 64/400\n",
            "514/514 [==============================] - 0s 498us/step - loss: 0.5187 - acc: 0.7393 - val_loss: 0.5789 - val_acc: 0.7087\n",
            "Epoch 65/400\n",
            "514/514 [==============================] - 0s 428us/step - loss: 0.5143 - acc: 0.7393 - val_loss: 0.5707 - val_acc: 0.7205\n",
            "Epoch 66/400\n",
            "514/514 [==============================] - 0s 423us/step - loss: 0.5143 - acc: 0.7510 - val_loss: 0.5542 - val_acc: 0.7362\n",
            "Epoch 67/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.5140 - acc: 0.7412 - val_loss: 0.5582 - val_acc: 0.7283\n",
            "Epoch 68/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.5111 - acc: 0.7626 - val_loss: 0.5733 - val_acc: 0.7165\n",
            "Epoch 69/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.5156 - acc: 0.7529 - val_loss: 0.5615 - val_acc: 0.7598\n",
            "Epoch 70/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.5146 - acc: 0.7412 - val_loss: 0.5941 - val_acc: 0.6850\n",
            "Epoch 71/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.5063 - acc: 0.7510 - val_loss: 0.5403 - val_acc: 0.7244\n",
            "Epoch 72/400\n",
            "514/514 [==============================] - 0s 422us/step - loss: 0.5049 - acc: 0.7374 - val_loss: 0.5528 - val_acc: 0.7283\n",
            "Epoch 73/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.5152 - acc: 0.7471 - val_loss: 0.5544 - val_acc: 0.7402\n",
            "Epoch 74/400\n",
            "514/514 [==============================] - 0s 457us/step - loss: 0.5039 - acc: 0.7568 - val_loss: 0.5472 - val_acc: 0.7677\n",
            "Epoch 75/400\n",
            "514/514 [==============================] - 0s 423us/step - loss: 0.5067 - acc: 0.7568 - val_loss: 0.5361 - val_acc: 0.7283\n",
            "Epoch 76/400\n",
            "514/514 [==============================] - 0s 429us/step - loss: 0.5057 - acc: 0.7510 - val_loss: 0.5488 - val_acc: 0.7126\n",
            "Epoch 77/400\n",
            "514/514 [==============================] - 0s 457us/step - loss: 0.4987 - acc: 0.7510 - val_loss: 0.5695 - val_acc: 0.7165\n",
            "Epoch 78/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.5040 - acc: 0.7588 - val_loss: 0.5374 - val_acc: 0.7441\n",
            "Epoch 79/400\n",
            "514/514 [==============================] - 0s 429us/step - loss: 0.4937 - acc: 0.7665 - val_loss: 0.5419 - val_acc: 0.7441\n",
            "Epoch 80/400\n",
            "514/514 [==============================] - 0s 429us/step - loss: 0.4947 - acc: 0.7607 - val_loss: 0.5454 - val_acc: 0.7362\n",
            "Epoch 81/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.4922 - acc: 0.7510 - val_loss: 0.5472 - val_acc: 0.7598\n",
            "Epoch 82/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.5039 - acc: 0.7393 - val_loss: 0.5351 - val_acc: 0.7362\n",
            "Epoch 83/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.4897 - acc: 0.7529 - val_loss: 0.5574 - val_acc: 0.7362\n",
            "Epoch 84/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4949 - acc: 0.7568 - val_loss: 0.5377 - val_acc: 0.7480\n",
            "Epoch 85/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.4893 - acc: 0.7743 - val_loss: 0.5362 - val_acc: 0.7165\n",
            "Epoch 86/400\n",
            "514/514 [==============================] - 0s 460us/step - loss: 0.4962 - acc: 0.7588 - val_loss: 0.5439 - val_acc: 0.6929\n",
            "Epoch 87/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4886 - acc: 0.7607 - val_loss: 0.5366 - val_acc: 0.7520\n",
            "Epoch 88/400\n",
            "514/514 [==============================] - 0s 434us/step - loss: 0.4920 - acc: 0.7724 - val_loss: 0.5490 - val_acc: 0.7323\n",
            "Epoch 89/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.5066 - acc: 0.7588 - val_loss: 0.5611 - val_acc: 0.7480\n",
            "Epoch 90/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.4975 - acc: 0.7529 - val_loss: 0.5411 - val_acc: 0.7559\n",
            "Epoch 91/400\n",
            "514/514 [==============================] - 0s 462us/step - loss: 0.4809 - acc: 0.7685 - val_loss: 0.5321 - val_acc: 0.7559\n",
            "Epoch 92/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.4909 - acc: 0.7568 - val_loss: 0.5738 - val_acc: 0.7087\n",
            "Epoch 93/400\n",
            "514/514 [==============================] - 0s 431us/step - loss: 0.4825 - acc: 0.7724 - val_loss: 0.5408 - val_acc: 0.7362\n",
            "Epoch 94/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.4928 - acc: 0.7588 - val_loss: 0.5362 - val_acc: 0.7480\n",
            "Epoch 95/400\n",
            "514/514 [==============================] - 0s 450us/step - loss: 0.4707 - acc: 0.7626 - val_loss: 0.5581 - val_acc: 0.7559\n",
            "Epoch 96/400\n",
            "514/514 [==============================] - 0s 456us/step - loss: 0.4825 - acc: 0.7802 - val_loss: 0.5324 - val_acc: 0.7756\n",
            "Epoch 97/400\n",
            "514/514 [==============================] - 0s 423us/step - loss: 0.4761 - acc: 0.7665 - val_loss: 0.5598 - val_acc: 0.7559\n",
            "Epoch 98/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.4886 - acc: 0.7665 - val_loss: 0.5368 - val_acc: 0.7402\n",
            "Epoch 99/400\n",
            "514/514 [==============================] - 0s 483us/step - loss: 0.4792 - acc: 0.7607 - val_loss: 0.5402 - val_acc: 0.7638\n",
            "Epoch 100/400\n",
            "514/514 [==============================] - 0s 431us/step - loss: 0.4755 - acc: 0.7704 - val_loss: 0.5487 - val_acc: 0.7520\n",
            "Epoch 101/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4830 - acc: 0.7549 - val_loss: 0.5330 - val_acc: 0.7559\n",
            "Epoch 102/400\n",
            "514/514 [==============================] - 0s 456us/step - loss: 0.4913 - acc: 0.7626 - val_loss: 0.5264 - val_acc: 0.7441\n",
            "Epoch 103/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.4789 - acc: 0.7899 - val_loss: 0.5415 - val_acc: 0.7756\n",
            "Epoch 104/400\n",
            "514/514 [==============================] - 0s 493us/step - loss: 0.4783 - acc: 0.7782 - val_loss: 0.5506 - val_acc: 0.7362\n",
            "Epoch 105/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.4919 - acc: 0.7879 - val_loss: 0.5373 - val_acc: 0.7362\n",
            "Epoch 106/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.4737 - acc: 0.7704 - val_loss: 0.5380 - val_acc: 0.7402\n",
            "Epoch 107/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.4717 - acc: 0.7821 - val_loss: 0.5653 - val_acc: 0.7402\n",
            "Epoch 108/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.4731 - acc: 0.7938 - val_loss: 0.5403 - val_acc: 0.7480\n",
            "Epoch 109/400\n",
            "514/514 [==============================] - 0s 466us/step - loss: 0.4921 - acc: 0.7588 - val_loss: 0.5512 - val_acc: 0.7323\n",
            "Epoch 110/400\n",
            "514/514 [==============================] - 0s 484us/step - loss: 0.4819 - acc: 0.7724 - val_loss: 0.5750 - val_acc: 0.7283\n",
            "Epoch 111/400\n",
            "514/514 [==============================] - 0s 461us/step - loss: 0.4720 - acc: 0.7782 - val_loss: 0.5396 - val_acc: 0.7323\n",
            "Epoch 112/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.4575 - acc: 0.7840 - val_loss: 0.5558 - val_acc: 0.7480\n",
            "Epoch 113/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.4653 - acc: 0.7782 - val_loss: 0.5323 - val_acc: 0.7441\n",
            "Epoch 114/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.4746 - acc: 0.7646 - val_loss: 0.5375 - val_acc: 0.7520\n",
            "Epoch 115/400\n",
            "514/514 [==============================] - 0s 460us/step - loss: 0.4657 - acc: 0.7840 - val_loss: 0.5455 - val_acc: 0.7441\n",
            "Epoch 116/400\n",
            "514/514 [==============================] - 0s 429us/step - loss: 0.4631 - acc: 0.7860 - val_loss: 0.5413 - val_acc: 0.7598\n",
            "Epoch 117/400\n",
            "514/514 [==============================] - 0s 474us/step - loss: 0.4615 - acc: 0.7821 - val_loss: 0.5448 - val_acc: 0.7441\n",
            "Epoch 118/400\n",
            "514/514 [==============================] - 0s 450us/step - loss: 0.4562 - acc: 0.7821 - val_loss: 0.5491 - val_acc: 0.7402\n",
            "Epoch 119/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4633 - acc: 0.7802 - val_loss: 0.5491 - val_acc: 0.7480\n",
            "Epoch 120/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4635 - acc: 0.7802 - val_loss: 0.5489 - val_acc: 0.7480\n",
            "Epoch 121/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.4503 - acc: 0.7996 - val_loss: 0.5532 - val_acc: 0.7165\n",
            "Epoch 122/400\n",
            "514/514 [==============================] - 0s 473us/step - loss: 0.4794 - acc: 0.7607 - val_loss: 0.5492 - val_acc: 0.7323\n",
            "Epoch 123/400\n",
            "514/514 [==============================] - 0s 465us/step - loss: 0.4497 - acc: 0.7977 - val_loss: 0.5949 - val_acc: 0.7126\n",
            "Epoch 124/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.4544 - acc: 0.7977 - val_loss: 0.5559 - val_acc: 0.7520\n",
            "Epoch 125/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4504 - acc: 0.8016 - val_loss: 0.5654 - val_acc: 0.7402\n",
            "Epoch 126/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.4415 - acc: 0.7996 - val_loss: 0.5578 - val_acc: 0.7638\n",
            "Epoch 127/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.4430 - acc: 0.8113 - val_loss: 0.5713 - val_acc: 0.7283\n",
            "Epoch 128/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.4594 - acc: 0.8054 - val_loss: 0.5433 - val_acc: 0.7323\n",
            "Epoch 129/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4507 - acc: 0.7938 - val_loss: 0.5538 - val_acc: 0.7402\n",
            "Epoch 130/400\n",
            "514/514 [==============================] - 0s 453us/step - loss: 0.4454 - acc: 0.8035 - val_loss: 0.5379 - val_acc: 0.7717\n",
            "Epoch 131/400\n",
            "514/514 [==============================] - 0s 431us/step - loss: 0.4528 - acc: 0.7957 - val_loss: 0.5606 - val_acc: 0.7283\n",
            "Epoch 132/400\n",
            "514/514 [==============================] - 0s 482us/step - loss: 0.4445 - acc: 0.7957 - val_loss: 0.5573 - val_acc: 0.7283\n",
            "Epoch 133/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.4429 - acc: 0.8113 - val_loss: 0.6254 - val_acc: 0.6929\n",
            "Epoch 134/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.4728 - acc: 0.7840 - val_loss: 0.5701 - val_acc: 0.7244\n",
            "Epoch 135/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4429 - acc: 0.8074 - val_loss: 0.5426 - val_acc: 0.7638\n",
            "Epoch 136/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.4365 - acc: 0.8016 - val_loss: 0.5720 - val_acc: 0.7559\n",
            "Epoch 137/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.4622 - acc: 0.7899 - val_loss: 0.5424 - val_acc: 0.7638\n",
            "Epoch 138/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.4296 - acc: 0.8093 - val_loss: 0.5561 - val_acc: 0.7520\n",
            "Epoch 139/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4427 - acc: 0.7938 - val_loss: 0.5356 - val_acc: 0.7520\n",
            "Epoch 140/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.4334 - acc: 0.8132 - val_loss: 0.5866 - val_acc: 0.7165\n",
            "Epoch 141/400\n",
            "514/514 [==============================] - 0s 450us/step - loss: 0.4333 - acc: 0.7957 - val_loss: 0.5558 - val_acc: 0.7480\n",
            "Epoch 142/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4352 - acc: 0.7918 - val_loss: 0.5435 - val_acc: 0.7441\n",
            "Epoch 143/400\n",
            "514/514 [==============================] - 0s 484us/step - loss: 0.4322 - acc: 0.8035 - val_loss: 0.5898 - val_acc: 0.7244\n",
            "Epoch 144/400\n",
            "514/514 [==============================] - 0s 490us/step - loss: 0.4337 - acc: 0.8016 - val_loss: 0.5531 - val_acc: 0.7598\n",
            "Epoch 145/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.4232 - acc: 0.8035 - val_loss: 0.5489 - val_acc: 0.7441\n",
            "Epoch 146/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.4329 - acc: 0.7899 - val_loss: 0.6107 - val_acc: 0.6850\n",
            "Epoch 147/400\n",
            "514/514 [==============================] - 0s 462us/step - loss: 0.4465 - acc: 0.8016 - val_loss: 0.5753 - val_acc: 0.7441\n",
            "Epoch 148/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.4379 - acc: 0.8054 - val_loss: 0.5852 - val_acc: 0.7441\n",
            "Epoch 149/400\n",
            "514/514 [==============================] - 0s 426us/step - loss: 0.4293 - acc: 0.8035 - val_loss: 0.5463 - val_acc: 0.7559\n",
            "Epoch 150/400\n",
            "514/514 [==============================] - 0s 423us/step - loss: 0.4373 - acc: 0.7918 - val_loss: 0.6026 - val_acc: 0.7165\n",
            "Epoch 151/400\n",
            "514/514 [==============================] - 0s 434us/step - loss: 0.4485 - acc: 0.7957 - val_loss: 0.5702 - val_acc: 0.7244\n",
            "Epoch 152/400\n",
            "514/514 [==============================] - 0s 484us/step - loss: 0.4289 - acc: 0.8074 - val_loss: 0.5515 - val_acc: 0.7559\n",
            "Epoch 153/400\n",
            "514/514 [==============================] - 0s 427us/step - loss: 0.4372 - acc: 0.7899 - val_loss: 0.6077 - val_acc: 0.7520\n",
            "Epoch 154/400\n",
            "514/514 [==============================] - 0s 426us/step - loss: 0.4485 - acc: 0.7899 - val_loss: 0.5422 - val_acc: 0.7677\n",
            "Epoch 155/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.4306 - acc: 0.7977 - val_loss: 0.5761 - val_acc: 0.7283\n",
            "Epoch 156/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.4317 - acc: 0.7879 - val_loss: 0.5465 - val_acc: 0.7480\n",
            "Epoch 157/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.4294 - acc: 0.8054 - val_loss: 0.5529 - val_acc: 0.7480\n",
            "Epoch 158/400\n",
            "514/514 [==============================] - 0s 462us/step - loss: 0.4289 - acc: 0.8054 - val_loss: 0.5660 - val_acc: 0.7323\n",
            "Epoch 159/400\n",
            "514/514 [==============================] - 0s 453us/step - loss: 0.4327 - acc: 0.7918 - val_loss: 0.5723 - val_acc: 0.7520\n",
            "Epoch 160/400\n",
            "514/514 [==============================] - 0s 461us/step - loss: 0.4347 - acc: 0.7918 - val_loss: 0.5871 - val_acc: 0.7283\n",
            "Epoch 161/400\n",
            "514/514 [==============================] - 0s 460us/step - loss: 0.4565 - acc: 0.7918 - val_loss: 0.5625 - val_acc: 0.7323\n",
            "Epoch 162/400\n",
            "514/514 [==============================] - 0s 472us/step - loss: 0.4161 - acc: 0.8191 - val_loss: 0.5561 - val_acc: 0.7402\n",
            "Epoch 163/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.4147 - acc: 0.8054 - val_loss: 0.5790 - val_acc: 0.7165\n",
            "Epoch 164/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.4356 - acc: 0.7957 - val_loss: 0.5635 - val_acc: 0.7638\n",
            "Epoch 165/400\n",
            "514/514 [==============================] - 0s 471us/step - loss: 0.4282 - acc: 0.8016 - val_loss: 0.5617 - val_acc: 0.7559\n",
            "Epoch 166/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.4190 - acc: 0.8132 - val_loss: 0.5749 - val_acc: 0.7480\n",
            "Epoch 167/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4121 - acc: 0.8191 - val_loss: 0.5672 - val_acc: 0.7598\n",
            "Epoch 168/400\n",
            "514/514 [==============================] - 0s 450us/step - loss: 0.4426 - acc: 0.7938 - val_loss: 0.6162 - val_acc: 0.7165\n",
            "Epoch 169/400\n",
            "514/514 [==============================] - 0s 460us/step - loss: 0.4228 - acc: 0.8113 - val_loss: 0.5790 - val_acc: 0.7520\n",
            "Epoch 170/400\n",
            "514/514 [==============================] - 0s 456us/step - loss: 0.4246 - acc: 0.8035 - val_loss: 0.5791 - val_acc: 0.7441\n",
            "Epoch 171/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.4464 - acc: 0.7840 - val_loss: 0.5738 - val_acc: 0.7441\n",
            "Epoch 172/400\n",
            "514/514 [==============================] - 0s 456us/step - loss: 0.4228 - acc: 0.7996 - val_loss: 0.5716 - val_acc: 0.7441\n",
            "Epoch 173/400\n",
            "514/514 [==============================] - 0s 428us/step - loss: 0.4326 - acc: 0.7957 - val_loss: 0.5765 - val_acc: 0.7598\n",
            "Epoch 174/400\n",
            "514/514 [==============================] - 0s 474us/step - loss: 0.4144 - acc: 0.8249 - val_loss: 0.5717 - val_acc: 0.7402\n",
            "Epoch 175/400\n",
            "514/514 [==============================] - 0s 428us/step - loss: 0.4069 - acc: 0.8152 - val_loss: 0.5703 - val_acc: 0.7402\n",
            "Epoch 176/400\n",
            "514/514 [==============================] - 0s 408us/step - loss: 0.4154 - acc: 0.8016 - val_loss: 0.6027 - val_acc: 0.7283\n",
            "Epoch 177/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4193 - acc: 0.7996 - val_loss: 0.5752 - val_acc: 0.7362\n",
            "Epoch 178/400\n",
            "514/514 [==============================] - 0s 481us/step - loss: 0.4093 - acc: 0.8054 - val_loss: 0.5939 - val_acc: 0.7244\n",
            "Epoch 179/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.4162 - acc: 0.8054 - val_loss: 0.5808 - val_acc: 0.7559\n",
            "Epoch 180/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.4292 - acc: 0.7938 - val_loss: 0.5914 - val_acc: 0.7441\n",
            "Epoch 181/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.4096 - acc: 0.8093 - val_loss: 0.5999 - val_acc: 0.7362\n",
            "Epoch 182/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.4486 - acc: 0.7782 - val_loss: 0.6018 - val_acc: 0.7598\n",
            "Epoch 183/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.4047 - acc: 0.8210 - val_loss: 0.5862 - val_acc: 0.7559\n",
            "Epoch 184/400\n",
            "514/514 [==============================] - 0s 453us/step - loss: 0.4041 - acc: 0.8152 - val_loss: 0.5845 - val_acc: 0.7441\n",
            "Epoch 185/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.4107 - acc: 0.8191 - val_loss: 0.6001 - val_acc: 0.7480\n",
            "Epoch 186/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.4075 - acc: 0.8191 - val_loss: 0.5852 - val_acc: 0.7441\n",
            "Epoch 187/400\n",
            "514/514 [==============================] - 0s 524us/step - loss: 0.4090 - acc: 0.8171 - val_loss: 0.5785 - val_acc: 0.7441\n",
            "Epoch 188/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.4021 - acc: 0.8171 - val_loss: 0.6120 - val_acc: 0.7480\n",
            "Epoch 189/400\n",
            "514/514 [==============================] - 0s 485us/step - loss: 0.4310 - acc: 0.8016 - val_loss: 0.6003 - val_acc: 0.7480\n",
            "Epoch 190/400\n",
            "514/514 [==============================] - 0s 463us/step - loss: 0.4340 - acc: 0.7996 - val_loss: 0.6285 - val_acc: 0.7402\n",
            "Epoch 191/400\n",
            "514/514 [==============================] - 0s 480us/step - loss: 0.4183 - acc: 0.7996 - val_loss: 0.5777 - val_acc: 0.7559\n",
            "Epoch 192/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.4041 - acc: 0.8366 - val_loss: 0.5770 - val_acc: 0.7520\n",
            "Epoch 193/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3997 - acc: 0.8210 - val_loss: 0.5739 - val_acc: 0.7559\n",
            "Epoch 194/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.4002 - acc: 0.8230 - val_loss: 0.5875 - val_acc: 0.7598\n",
            "Epoch 195/400\n",
            "514/514 [==============================] - 0s 479us/step - loss: 0.4075 - acc: 0.8093 - val_loss: 0.5813 - val_acc: 0.7402\n",
            "Epoch 196/400\n",
            "514/514 [==============================] - 0s 457us/step - loss: 0.4303 - acc: 0.7996 - val_loss: 0.6245 - val_acc: 0.7638\n",
            "Epoch 197/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.4447 - acc: 0.7938 - val_loss: 0.6488 - val_acc: 0.7598\n",
            "Epoch 198/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.4135 - acc: 0.8132 - val_loss: 0.5951 - val_acc: 0.7559\n",
            "Epoch 199/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.3942 - acc: 0.8210 - val_loss: 0.6439 - val_acc: 0.7205\n",
            "Epoch 200/400\n",
            "514/514 [==============================] - 0s 487us/step - loss: 0.4148 - acc: 0.8054 - val_loss: 0.6323 - val_acc: 0.7362\n",
            "Epoch 201/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3981 - acc: 0.8288 - val_loss: 0.6106 - val_acc: 0.7638\n",
            "Epoch 202/400\n",
            "514/514 [==============================] - 0s 427us/step - loss: 0.4050 - acc: 0.8171 - val_loss: 0.6069 - val_acc: 0.7638\n",
            "Epoch 203/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.4039 - acc: 0.8093 - val_loss: 0.6206 - val_acc: 0.7323\n",
            "Epoch 204/400\n",
            "514/514 [==============================] - 0s 457us/step - loss: 0.3935 - acc: 0.8152 - val_loss: 0.6140 - val_acc: 0.7520\n",
            "Epoch 205/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.4031 - acc: 0.8171 - val_loss: 0.6055 - val_acc: 0.7480\n",
            "Epoch 206/400\n",
            "514/514 [==============================] - 0s 466us/step - loss: 0.3875 - acc: 0.8307 - val_loss: 0.6821 - val_acc: 0.7087\n",
            "Epoch 207/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.3969 - acc: 0.8191 - val_loss: 0.6214 - val_acc: 0.7441\n",
            "Epoch 208/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.3925 - acc: 0.8113 - val_loss: 0.6120 - val_acc: 0.7520\n",
            "Epoch 209/400\n",
            "514/514 [==============================] - 0s 462us/step - loss: 0.4046 - acc: 0.8074 - val_loss: 0.6268 - val_acc: 0.7441\n",
            "Epoch 210/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.3898 - acc: 0.8268 - val_loss: 0.6193 - val_acc: 0.7441\n",
            "Epoch 211/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.3986 - acc: 0.8074 - val_loss: 0.6298 - val_acc: 0.7441\n",
            "Epoch 212/400\n",
            "514/514 [==============================] - 0s 458us/step - loss: 0.3938 - acc: 0.8054 - val_loss: 0.6353 - val_acc: 0.7480\n",
            "Epoch 213/400\n",
            "514/514 [==============================] - 0s 467us/step - loss: 0.3917 - acc: 0.8054 - val_loss: 0.6611 - val_acc: 0.7480\n",
            "Epoch 214/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3967 - acc: 0.8171 - val_loss: 0.6150 - val_acc: 0.7520\n",
            "Epoch 215/400\n",
            "514/514 [==============================] - 0s 456us/step - loss: 0.3876 - acc: 0.8346 - val_loss: 0.6469 - val_acc: 0.7323\n",
            "Epoch 216/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.4027 - acc: 0.8054 - val_loss: 0.6437 - val_acc: 0.7441\n",
            "Epoch 217/400\n",
            "514/514 [==============================] - 0s 428us/step - loss: 0.5002 - acc: 0.7840 - val_loss: 0.6640 - val_acc: 0.7047\n",
            "Epoch 218/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.4113 - acc: 0.8132 - val_loss: 0.6737 - val_acc: 0.7402\n",
            "Epoch 219/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.4024 - acc: 0.8132 - val_loss: 0.6350 - val_acc: 0.7480\n",
            "Epoch 220/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.3940 - acc: 0.8054 - val_loss: 0.6575 - val_acc: 0.7402\n",
            "Epoch 221/400\n",
            "514/514 [==============================] - 0s 430us/step - loss: 0.3883 - acc: 0.8210 - val_loss: 0.6574 - val_acc: 0.7638\n",
            "Epoch 222/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.4016 - acc: 0.8093 - val_loss: 0.6792 - val_acc: 0.7283\n",
            "Epoch 223/400\n",
            "514/514 [==============================] - 0s 466us/step - loss: 0.3968 - acc: 0.8093 - val_loss: 0.6706 - val_acc: 0.7480\n",
            "Epoch 224/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.3926 - acc: 0.8230 - val_loss: 0.6215 - val_acc: 0.7559\n",
            "Epoch 225/400\n",
            "514/514 [==============================] - 0s 486us/step - loss: 0.3830 - acc: 0.8210 - val_loss: 0.6490 - val_acc: 0.7323\n",
            "Epoch 226/400\n",
            "514/514 [==============================] - 0s 470us/step - loss: 0.3847 - acc: 0.8210 - val_loss: 0.6527 - val_acc: 0.7441\n",
            "Epoch 227/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3851 - acc: 0.8191 - val_loss: 0.6457 - val_acc: 0.7362\n",
            "Epoch 228/400\n",
            "514/514 [==============================] - 0s 425us/step - loss: 0.3948 - acc: 0.8210 - val_loss: 0.6600 - val_acc: 0.7362\n",
            "Epoch 229/400\n",
            "514/514 [==============================] - 0s 428us/step - loss: 0.3786 - acc: 0.8385 - val_loss: 0.6482 - val_acc: 0.7559\n",
            "Epoch 230/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.3929 - acc: 0.8054 - val_loss: 0.6616 - val_acc: 0.7480\n",
            "Epoch 231/400\n",
            "514/514 [==============================] - 0s 453us/step - loss: 0.4202 - acc: 0.8016 - val_loss: 0.6716 - val_acc: 0.7520\n",
            "Epoch 232/400\n",
            "514/514 [==============================] - 0s 463us/step - loss: 0.4053 - acc: 0.8113 - val_loss: 0.7030 - val_acc: 0.7165\n",
            "Epoch 233/400\n",
            "514/514 [==============================] - 0s 473us/step - loss: 0.3900 - acc: 0.8249 - val_loss: 0.6849 - val_acc: 0.7441\n",
            "Epoch 234/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3948 - acc: 0.7996 - val_loss: 0.6995 - val_acc: 0.7323\n",
            "Epoch 235/400\n",
            "514/514 [==============================] - 0s 476us/step - loss: 0.4033 - acc: 0.8132 - val_loss: 0.6955 - val_acc: 0.7283\n",
            "Epoch 236/400\n",
            "514/514 [==============================] - 0s 431us/step - loss: 0.3883 - acc: 0.8171 - val_loss: 0.6922 - val_acc: 0.7559\n",
            "Epoch 237/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3865 - acc: 0.8230 - val_loss: 0.6612 - val_acc: 0.7244\n",
            "Epoch 238/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.3807 - acc: 0.8152 - val_loss: 0.6965 - val_acc: 0.7520\n",
            "Epoch 239/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3898 - acc: 0.8249 - val_loss: 0.6535 - val_acc: 0.7559\n",
            "Epoch 240/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.3889 - acc: 0.8113 - val_loss: 0.6456 - val_acc: 0.7559\n",
            "Epoch 241/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.3729 - acc: 0.8307 - val_loss: 0.6684 - val_acc: 0.7362\n",
            "Epoch 242/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.3767 - acc: 0.8230 - val_loss: 0.6758 - val_acc: 0.7559\n",
            "Epoch 243/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3774 - acc: 0.8230 - val_loss: 0.6600 - val_acc: 0.7480\n",
            "Epoch 244/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.3726 - acc: 0.8230 - val_loss: 0.7078 - val_acc: 0.7047\n",
            "Epoch 245/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3921 - acc: 0.8113 - val_loss: 0.6659 - val_acc: 0.7441\n",
            "Epoch 246/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.3686 - acc: 0.8288 - val_loss: 0.7123 - val_acc: 0.7244\n",
            "Epoch 247/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.3682 - acc: 0.8268 - val_loss: 0.6870 - val_acc: 0.7362\n",
            "Epoch 248/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.3782 - acc: 0.8113 - val_loss: 0.6873 - val_acc: 0.7402\n",
            "Epoch 249/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.3795 - acc: 0.8171 - val_loss: 0.6771 - val_acc: 0.7323\n",
            "Epoch 250/400\n",
            "514/514 [==============================] - 0s 477us/step - loss: 0.3902 - acc: 0.8346 - val_loss: 0.6502 - val_acc: 0.7598\n",
            "Epoch 251/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.3691 - acc: 0.8307 - val_loss: 0.6763 - val_acc: 0.7402\n",
            "Epoch 252/400\n",
            "514/514 [==============================] - 0s 430us/step - loss: 0.3936 - acc: 0.8152 - val_loss: 0.6764 - val_acc: 0.7638\n",
            "Epoch 253/400\n",
            "514/514 [==============================] - 0s 476us/step - loss: 0.3723 - acc: 0.8191 - val_loss: 0.6826 - val_acc: 0.7441\n",
            "Epoch 254/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3919 - acc: 0.8093 - val_loss: 0.6947 - val_acc: 0.7559\n",
            "Epoch 255/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3671 - acc: 0.8346 - val_loss: 0.6739 - val_acc: 0.7520\n",
            "Epoch 256/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.3867 - acc: 0.8074 - val_loss: 0.6714 - val_acc: 0.7480\n",
            "Epoch 257/400\n",
            "514/514 [==============================] - 0s 490us/step - loss: 0.3778 - acc: 0.8268 - val_loss: 0.6964 - val_acc: 0.7323\n",
            "Epoch 258/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3683 - acc: 0.8346 - val_loss: 0.6801 - val_acc: 0.7520\n",
            "Epoch 259/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.3724 - acc: 0.8288 - val_loss: 0.6932 - val_acc: 0.7559\n",
            "Epoch 260/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3741 - acc: 0.8171 - val_loss: 0.7083 - val_acc: 0.7480\n",
            "Epoch 261/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3716 - acc: 0.8424 - val_loss: 0.6729 - val_acc: 0.7441\n",
            "Epoch 262/400\n",
            "514/514 [==============================] - 0s 446us/step - loss: 0.3613 - acc: 0.8463 - val_loss: 0.6650 - val_acc: 0.7520\n",
            "Epoch 263/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.3618 - acc: 0.8366 - val_loss: 0.6791 - val_acc: 0.7441\n",
            "Epoch 264/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.3690 - acc: 0.8268 - val_loss: 0.6566 - val_acc: 0.7480\n",
            "Epoch 265/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.3627 - acc: 0.8288 - val_loss: 0.7169 - val_acc: 0.7402\n",
            "Epoch 266/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.3763 - acc: 0.8191 - val_loss: 0.6946 - val_acc: 0.7441\n",
            "Epoch 267/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3650 - acc: 0.8405 - val_loss: 0.6586 - val_acc: 0.7598\n",
            "Epoch 268/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.3642 - acc: 0.8288 - val_loss: 0.7321 - val_acc: 0.7323\n",
            "Epoch 269/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3658 - acc: 0.8327 - val_loss: 0.6996 - val_acc: 0.7480\n",
            "Epoch 270/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.3775 - acc: 0.8230 - val_loss: 0.7630 - val_acc: 0.7126\n",
            "Epoch 271/400\n",
            "514/514 [==============================] - 0s 429us/step - loss: 0.4752 - acc: 0.7743 - val_loss: 0.6564 - val_acc: 0.7441\n",
            "Epoch 272/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.3811 - acc: 0.8366 - val_loss: 0.7685 - val_acc: 0.7638\n",
            "Epoch 273/400\n",
            "514/514 [==============================] - 0s 467us/step - loss: 0.3983 - acc: 0.8191 - val_loss: 0.6989 - val_acc: 0.7520\n",
            "Epoch 274/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3683 - acc: 0.8210 - val_loss: 0.7225 - val_acc: 0.7244\n",
            "Epoch 275/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.3630 - acc: 0.8268 - val_loss: 0.7346 - val_acc: 0.7323\n",
            "Epoch 276/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3681 - acc: 0.8230 - val_loss: 0.7013 - val_acc: 0.7520\n",
            "Epoch 277/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3630 - acc: 0.8346 - val_loss: 0.7262 - val_acc: 0.7362\n",
            "Epoch 278/400\n",
            "514/514 [==============================] - 0s 434us/step - loss: 0.3628 - acc: 0.8405 - val_loss: 0.6812 - val_acc: 0.7559\n",
            "Epoch 279/400\n",
            "514/514 [==============================] - 0s 488us/step - loss: 0.3691 - acc: 0.8346 - val_loss: 0.7065 - val_acc: 0.7283\n",
            "Epoch 280/400\n",
            "514/514 [==============================] - 0s 480us/step - loss: 0.3748 - acc: 0.8171 - val_loss: 0.6640 - val_acc: 0.7559\n",
            "Epoch 281/400\n",
            "514/514 [==============================] - 0s 461us/step - loss: 0.3631 - acc: 0.8463 - val_loss: 0.6603 - val_acc: 0.7480\n",
            "Epoch 282/400\n",
            "514/514 [==============================] - 0s 460us/step - loss: 0.3710 - acc: 0.8385 - val_loss: 0.7125 - val_acc: 0.7244\n",
            "Epoch 283/400\n",
            "514/514 [==============================] - 0s 474us/step - loss: 0.3564 - acc: 0.8230 - val_loss: 0.6872 - val_acc: 0.7480\n",
            "Epoch 284/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.4403 - acc: 0.8054 - val_loss: 0.6201 - val_acc: 0.7441\n",
            "Epoch 285/400\n",
            "514/514 [==============================] - 0s 460us/step - loss: 0.4070 - acc: 0.8074 - val_loss: 0.7189 - val_acc: 0.7441\n",
            "Epoch 286/400\n",
            "514/514 [==============================] - 0s 461us/step - loss: 0.3742 - acc: 0.8249 - val_loss: 0.6901 - val_acc: 0.7441\n",
            "Epoch 287/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3675 - acc: 0.8249 - val_loss: 0.6964 - val_acc: 0.7598\n",
            "Epoch 288/400\n",
            "514/514 [==============================] - 0s 491us/step - loss: 0.3881 - acc: 0.8191 - val_loss: 0.7075 - val_acc: 0.7441\n",
            "Epoch 289/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.3684 - acc: 0.8132 - val_loss: 0.6738 - val_acc: 0.7598\n",
            "Epoch 290/400\n",
            "514/514 [==============================] - 0s 467us/step - loss: 0.3574 - acc: 0.8482 - val_loss: 0.7063 - val_acc: 0.7244\n",
            "Epoch 291/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.3551 - acc: 0.8346 - val_loss: 0.6906 - val_acc: 0.7283\n",
            "Epoch 292/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.3705 - acc: 0.8268 - val_loss: 0.7104 - val_acc: 0.7402\n",
            "Epoch 293/400\n",
            "514/514 [==============================] - 0s 467us/step - loss: 0.3588 - acc: 0.8093 - val_loss: 0.6878 - val_acc: 0.7480\n",
            "Epoch 294/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3602 - acc: 0.8307 - val_loss: 0.7025 - val_acc: 0.7559\n",
            "Epoch 295/400\n",
            "514/514 [==============================] - 0s 474us/step - loss: 0.3663 - acc: 0.8307 - val_loss: 0.7329 - val_acc: 0.7244\n",
            "Epoch 296/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3592 - acc: 0.8366 - val_loss: 0.6946 - val_acc: 0.7480\n",
            "Epoch 297/400\n",
            "514/514 [==============================] - 0s 463us/step - loss: 0.3526 - acc: 0.8327 - val_loss: 0.7055 - val_acc: 0.7402\n",
            "Epoch 298/400\n",
            "514/514 [==============================] - 0s 453us/step - loss: 0.3509 - acc: 0.8463 - val_loss: 0.7011 - val_acc: 0.7559\n",
            "Epoch 299/400\n",
            "514/514 [==============================] - 0s 457us/step - loss: 0.3820 - acc: 0.8210 - val_loss: 0.7536 - val_acc: 0.7520\n",
            "Epoch 300/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.3792 - acc: 0.8152 - val_loss: 0.7437 - val_acc: 0.7402\n",
            "Epoch 301/400\n",
            "514/514 [==============================] - 0s 474us/step - loss: 0.3638 - acc: 0.8288 - val_loss: 0.6943 - val_acc: 0.7441\n",
            "Epoch 302/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.3590 - acc: 0.8385 - val_loss: 0.6959 - val_acc: 0.7441\n",
            "Epoch 303/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3472 - acc: 0.8288 - val_loss: 0.6931 - val_acc: 0.7598\n",
            "Epoch 304/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3522 - acc: 0.8346 - val_loss: 0.7572 - val_acc: 0.7323\n",
            "Epoch 305/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3686 - acc: 0.8346 - val_loss: 0.7520 - val_acc: 0.7008\n",
            "Epoch 306/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.3636 - acc: 0.8307 - val_loss: 0.6831 - val_acc: 0.7441\n",
            "Epoch 307/400\n",
            "514/514 [==============================] - 0s 430us/step - loss: 0.3631 - acc: 0.8268 - val_loss: 0.6957 - val_acc: 0.7598\n",
            "Epoch 308/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.3575 - acc: 0.8463 - val_loss: 0.7099 - val_acc: 0.7520\n",
            "Epoch 309/400\n",
            "514/514 [==============================] - 0s 483us/step - loss: 0.3627 - acc: 0.8385 - val_loss: 0.7227 - val_acc: 0.7480\n",
            "Epoch 310/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3435 - acc: 0.8405 - val_loss: 0.6996 - val_acc: 0.7480\n",
            "Epoch 311/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.3473 - acc: 0.8424 - val_loss: 0.6973 - val_acc: 0.7441\n",
            "Epoch 312/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.3431 - acc: 0.8482 - val_loss: 0.7191 - val_acc: 0.7441\n",
            "Epoch 313/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.3474 - acc: 0.8482 - val_loss: 0.7484 - val_acc: 0.7559\n",
            "Epoch 314/400\n",
            "514/514 [==============================] - 0s 481us/step - loss: 0.3739 - acc: 0.8171 - val_loss: 0.7370 - val_acc: 0.7441\n",
            "Epoch 315/400\n",
            "514/514 [==============================] - 0s 472us/step - loss: 0.3606 - acc: 0.8268 - val_loss: 0.7283 - val_acc: 0.7087\n",
            "Epoch 316/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3430 - acc: 0.8307 - val_loss: 0.7373 - val_acc: 0.7402\n",
            "Epoch 317/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.3531 - acc: 0.8210 - val_loss: 0.7118 - val_acc: 0.7362\n",
            "Epoch 318/400\n",
            "514/514 [==============================] - 0s 517us/step - loss: 0.3566 - acc: 0.8230 - val_loss: 0.7094 - val_acc: 0.7402\n",
            "Epoch 319/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.3443 - acc: 0.8424 - val_loss: 0.6993 - val_acc: 0.7323\n",
            "Epoch 320/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.3323 - acc: 0.8560 - val_loss: 0.7677 - val_acc: 0.7441\n",
            "Epoch 321/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3678 - acc: 0.8152 - val_loss: 0.7178 - val_acc: 0.7480\n",
            "Epoch 322/400\n",
            "514/514 [==============================] - 0s 504us/step - loss: 0.3479 - acc: 0.8288 - val_loss: 0.7075 - val_acc: 0.7559\n",
            "Epoch 323/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3364 - acc: 0.8444 - val_loss: 0.7569 - val_acc: 0.7323\n",
            "Epoch 324/400\n",
            "514/514 [==============================] - 0s 474us/step - loss: 0.3423 - acc: 0.8463 - val_loss: 0.7616 - val_acc: 0.7480\n",
            "Epoch 325/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.3430 - acc: 0.8385 - val_loss: 0.7545 - val_acc: 0.7480\n",
            "Epoch 326/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.3631 - acc: 0.8385 - val_loss: 0.7607 - val_acc: 0.7283\n",
            "Epoch 327/400\n",
            "514/514 [==============================] - 0s 466us/step - loss: 0.3519 - acc: 0.8230 - val_loss: 0.7874 - val_acc: 0.7165\n",
            "Epoch 328/400\n",
            "514/514 [==============================] - 0s 431us/step - loss: 0.3642 - acc: 0.8288 - val_loss: 0.7096 - val_acc: 0.7520\n",
            "Epoch 329/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.3431 - acc: 0.8210 - val_loss: 0.7120 - val_acc: 0.7441\n",
            "Epoch 330/400\n",
            "514/514 [==============================] - 0s 416us/step - loss: 0.3371 - acc: 0.8482 - val_loss: 0.7266 - val_acc: 0.7598\n",
            "Epoch 331/400\n",
            "514/514 [==============================] - 0s 465us/step - loss: 0.3364 - acc: 0.8444 - val_loss: 0.7194 - val_acc: 0.7677\n",
            "Epoch 332/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.3690 - acc: 0.8327 - val_loss: 0.7549 - val_acc: 0.7402\n",
            "Epoch 333/400\n",
            "514/514 [==============================] - 0s 442us/step - loss: 0.3640 - acc: 0.8191 - val_loss: 0.7480 - val_acc: 0.7559\n",
            "Epoch 334/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.3341 - acc: 0.8385 - val_loss: 0.7193 - val_acc: 0.7283\n",
            "Epoch 335/400\n",
            "514/514 [==============================] - 0s 434us/step - loss: 0.3437 - acc: 0.8307 - val_loss: 0.7822 - val_acc: 0.7520\n",
            "Epoch 336/400\n",
            "514/514 [==============================] - 0s 470us/step - loss: 0.3465 - acc: 0.8346 - val_loss: 0.7169 - val_acc: 0.7402\n",
            "Epoch 337/400\n",
            "514/514 [==============================] - 0s 443us/step - loss: 0.3488 - acc: 0.8346 - val_loss: 0.7766 - val_acc: 0.7402\n",
            "Epoch 338/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3529 - acc: 0.8327 - val_loss: 0.7121 - val_acc: 0.7402\n",
            "Epoch 339/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.3509 - acc: 0.8385 - val_loss: 0.7836 - val_acc: 0.7520\n",
            "Epoch 340/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.3615 - acc: 0.8366 - val_loss: 0.7310 - val_acc: 0.7441\n",
            "Epoch 341/400\n",
            "514/514 [==============================] - 0s 454us/step - loss: 0.3418 - acc: 0.8502 - val_loss: 0.7671 - val_acc: 0.7165\n",
            "Epoch 342/400\n",
            "514/514 [==============================] - 0s 438us/step - loss: 0.3579 - acc: 0.8171 - val_loss: 0.7212 - val_acc: 0.7677\n",
            "Epoch 343/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.3364 - acc: 0.8541 - val_loss: 0.7344 - val_acc: 0.7598\n",
            "Epoch 344/400\n",
            "514/514 [==============================] - 0s 480us/step - loss: 0.3270 - acc: 0.8521 - val_loss: 0.7229 - val_acc: 0.7520\n",
            "Epoch 345/400\n",
            "514/514 [==============================] - 0s 445us/step - loss: 0.3382 - acc: 0.8405 - val_loss: 0.8083 - val_acc: 0.7008\n",
            "Epoch 346/400\n",
            "514/514 [==============================] - 0s 420us/step - loss: 0.3567 - acc: 0.8307 - val_loss: 0.7200 - val_acc: 0.7441\n",
            "Epoch 347/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.3343 - acc: 0.8444 - val_loss: 0.7208 - val_acc: 0.7402\n",
            "Epoch 348/400\n",
            "514/514 [==============================] - 0s 429us/step - loss: 0.3639 - acc: 0.8230 - val_loss: 0.7291 - val_acc: 0.7283\n",
            "Epoch 349/400\n",
            "514/514 [==============================] - 0s 463us/step - loss: 0.3385 - acc: 0.8463 - val_loss: 0.7905 - val_acc: 0.7205\n",
            "Epoch 350/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3441 - acc: 0.8327 - val_loss: 0.7168 - val_acc: 0.7402\n",
            "Epoch 351/400\n",
            "514/514 [==============================] - 0s 461us/step - loss: 0.3236 - acc: 0.8696 - val_loss: 0.7589 - val_acc: 0.7087\n",
            "Epoch 352/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3584 - acc: 0.8210 - val_loss: 0.7779 - val_acc: 0.7441\n",
            "Epoch 353/400\n",
            "514/514 [==============================] - 0s 457us/step - loss: 0.3318 - acc: 0.8521 - val_loss: 0.7990 - val_acc: 0.7441\n",
            "Epoch 354/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3502 - acc: 0.8307 - val_loss: 0.7932 - val_acc: 0.7323\n",
            "Epoch 355/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.3774 - acc: 0.8366 - val_loss: 0.7247 - val_acc: 0.7520\n",
            "Epoch 356/400\n",
            "514/514 [==============================] - 0s 424us/step - loss: 0.3357 - acc: 0.8541 - val_loss: 0.7292 - val_acc: 0.7244\n",
            "Epoch 357/400\n",
            "514/514 [==============================] - 0s 444us/step - loss: 0.3369 - acc: 0.8619 - val_loss: 0.7231 - val_acc: 0.7441\n",
            "Epoch 358/400\n",
            "514/514 [==============================] - 0s 473us/step - loss: 0.3329 - acc: 0.8619 - val_loss: 0.7692 - val_acc: 0.7520\n",
            "Epoch 359/400\n",
            "514/514 [==============================] - 0s 458us/step - loss: 0.3873 - acc: 0.8230 - val_loss: 0.8471 - val_acc: 0.7205\n",
            "Epoch 360/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.3394 - acc: 0.8405 - val_loss: 0.7814 - val_acc: 0.7441\n",
            "Epoch 361/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.3272 - acc: 0.8521 - val_loss: 0.7948 - val_acc: 0.7402\n",
            "Epoch 362/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.3459 - acc: 0.8424 - val_loss: 0.6937 - val_acc: 0.7480\n",
            "Epoch 363/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3430 - acc: 0.8444 - val_loss: 0.7281 - val_acc: 0.7402\n",
            "Epoch 364/400\n",
            "514/514 [==============================] - 0s 452us/step - loss: 0.3373 - acc: 0.8444 - val_loss: 0.7862 - val_acc: 0.7520\n",
            "Epoch 365/400\n",
            "514/514 [==============================] - 0s 441us/step - loss: 0.3386 - acc: 0.8405 - val_loss: 0.7880 - val_acc: 0.7402\n",
            "Epoch 366/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.3291 - acc: 0.8405 - val_loss: 0.7496 - val_acc: 0.7362\n",
            "Epoch 367/400\n",
            "514/514 [==============================] - 0s 467us/step - loss: 0.3253 - acc: 0.8619 - val_loss: 0.7961 - val_acc: 0.7402\n",
            "Epoch 368/400\n",
            "514/514 [==============================] - 0s 462us/step - loss: 0.3316 - acc: 0.8424 - val_loss: 0.7712 - val_acc: 0.7244\n",
            "Epoch 369/400\n",
            "514/514 [==============================] - 0s 451us/step - loss: 0.3376 - acc: 0.8405 - val_loss: 0.7583 - val_acc: 0.7283\n",
            "Epoch 370/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.3331 - acc: 0.8521 - val_loss: 0.7518 - val_acc: 0.7244\n",
            "Epoch 371/400\n",
            "514/514 [==============================] - 0s 479us/step - loss: 0.3326 - acc: 0.8385 - val_loss: 0.7580 - val_acc: 0.7244\n",
            "Epoch 372/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.3374 - acc: 0.8307 - val_loss: 0.7729 - val_acc: 0.7362\n",
            "Epoch 373/400\n",
            "514/514 [==============================] - 0s 435us/step - loss: 0.3203 - acc: 0.8638 - val_loss: 0.8154 - val_acc: 0.7244\n",
            "Epoch 374/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.3354 - acc: 0.8366 - val_loss: 0.7781 - val_acc: 0.7087\n",
            "Epoch 375/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.3275 - acc: 0.8444 - val_loss: 0.7822 - val_acc: 0.7362\n",
            "Epoch 376/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.3297 - acc: 0.8638 - val_loss: 0.7507 - val_acc: 0.7362\n",
            "Epoch 377/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.3431 - acc: 0.8541 - val_loss: 0.7783 - val_acc: 0.7520\n",
            "Epoch 378/400\n",
            "514/514 [==============================] - 0s 459us/step - loss: 0.3206 - acc: 0.8560 - val_loss: 0.7865 - val_acc: 0.7559\n",
            "Epoch 379/400\n",
            "514/514 [==============================] - 0s 458us/step - loss: 0.3226 - acc: 0.8599 - val_loss: 0.7246 - val_acc: 0.7480\n",
            "Epoch 380/400\n",
            "514/514 [==============================] - 0s 464us/step - loss: 0.4199 - acc: 0.8152 - val_loss: 0.7221 - val_acc: 0.7126\n",
            "Epoch 381/400\n",
            "514/514 [==============================] - 0s 466us/step - loss: 0.3529 - acc: 0.8424 - val_loss: 0.7144 - val_acc: 0.7559\n",
            "Epoch 382/400\n",
            "514/514 [==============================] - 0s 478us/step - loss: 0.3356 - acc: 0.8424 - val_loss: 0.7756 - val_acc: 0.7520\n",
            "Epoch 383/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.3389 - acc: 0.8346 - val_loss: 0.7651 - val_acc: 0.7598\n",
            "Epoch 384/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3329 - acc: 0.8463 - val_loss: 0.7624 - val_acc: 0.7362\n",
            "Epoch 385/400\n",
            "514/514 [==============================] - 0s 433us/step - loss: 0.3172 - acc: 0.8599 - val_loss: 0.7759 - val_acc: 0.7559\n",
            "Epoch 386/400\n",
            "514/514 [==============================] - 0s 437us/step - loss: 0.3189 - acc: 0.8482 - val_loss: 0.7964 - val_acc: 0.7598\n",
            "Epoch 387/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.3218 - acc: 0.8638 - val_loss: 0.7953 - val_acc: 0.7283\n",
            "Epoch 388/400\n",
            "514/514 [==============================] - 0s 455us/step - loss: 0.3311 - acc: 0.8521 - val_loss: 0.7137 - val_acc: 0.7441\n",
            "Epoch 389/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3235 - acc: 0.8463 - val_loss: 0.7504 - val_acc: 0.7362\n",
            "Epoch 390/400\n",
            "514/514 [==============================] - 0s 436us/step - loss: 0.3598 - acc: 0.8346 - val_loss: 0.7572 - val_acc: 0.7205\n",
            "Epoch 391/400\n",
            "514/514 [==============================] - 0s 449us/step - loss: 0.4701 - acc: 0.8249 - val_loss: 0.7422 - val_acc: 0.6811\n",
            "Epoch 392/400\n",
            "514/514 [==============================] - 0s 419us/step - loss: 0.4170 - acc: 0.7918 - val_loss: 0.7269 - val_acc: 0.7283\n",
            "Epoch 393/400\n",
            "514/514 [==============================] - 0s 448us/step - loss: 0.3765 - acc: 0.8210 - val_loss: 0.6836 - val_acc: 0.7323\n",
            "Epoch 394/400\n",
            "514/514 [==============================] - 0s 440us/step - loss: 0.3584 - acc: 0.8327 - val_loss: 0.7015 - val_acc: 0.7362\n",
            "Epoch 395/400\n",
            "514/514 [==============================] - 0s 468us/step - loss: 0.3689 - acc: 0.8132 - val_loss: 0.6868 - val_acc: 0.7402\n",
            "Epoch 396/400\n",
            "514/514 [==============================] - 0s 439us/step - loss: 0.3627 - acc: 0.8307 - val_loss: 0.7680 - val_acc: 0.7126\n",
            "Epoch 397/400\n",
            "514/514 [==============================] - 0s 447us/step - loss: 0.3849 - acc: 0.8093 - val_loss: 0.6953 - val_acc: 0.7362\n",
            "Epoch 398/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.3448 - acc: 0.8444 - val_loss: 0.7375 - val_acc: 0.7677\n",
            "Epoch 399/400\n",
            "514/514 [==============================] - 0s 432us/step - loss: 0.3352 - acc: 0.8482 - val_loss: 0.7400 - val_acc: 0.7520\n",
            "Epoch 400/400\n",
            "514/514 [==============================] - 0s 458us/step - loss: 0.3483 - acc: 0.8366 - val_loss: 0.7210 - val_acc: 0.7638\n",
            "768/768 [==============================] - 0s 39us/step\n",
            "Accuracy: 82.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seqG4yreZmP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e3e7b809-db1f-4858-d192-9bd943f72d81"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRAkAH7QY8iQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "7c8d22ae-97c2-487f-c85f-e855e55c8bd2"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqIk8l/9USWQ1FWVAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p59vs6X7Evot",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v24i_ZZvUJC",
        "colab_type": "text"
      },
      "source": [
        "The variables can be summarized as follows:\n",
        "\n",
        "Input Variables (X):\n",
        "\n",
        "Number of times pregnant\n",
        "Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "Diastolic blood pressure (mm Hg)\n",
        "Triceps skin fold thickness (mm)\n",
        "2-Hour serum insulin (mu U/ml)\n",
        "Body mass index (weight in kg/(height in m)^2)\n",
        "Diabetes pedigree function\n",
        "Age (years)\n",
        "Output Variables (y):\n",
        "\n",
        "Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzw3jVcOw7kX",
        "colab_type": "code",
        "outputId": "7553e23b-e369-4995-c57c-7800532eb29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# first neural network with keras make predictions\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load the dataset\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "# make class predictions with the model\n",
        "predictions = model.predict_classes(X)\n",
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 0 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 0 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 0 (expected 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH8OOYsdG1fe",
        "colab_type": "code",
        "outputId": "26153eda-a85a-4875-ffda-6af5b847667b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load the dataset\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=8, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=450, batch_size=10)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/550\n",
            "768/768 [==============================] - 1s 803us/step - loss: 8.8632 - acc: 0.3750\n",
            "Epoch 2/550\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.7101 - acc: 0.6445\n",
            "Epoch 3/550\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.6735 - acc: 0.6510\n",
            "Epoch 4/550\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.6698 - acc: 0.6510\n",
            "Epoch 5/550\n",
            "768/768 [==============================] - 0s 380us/step - loss: 0.6689 - acc: 0.6510\n",
            "Epoch 6/550\n",
            "768/768 [==============================] - 0s 403us/step - loss: 0.6631 - acc: 0.6589\n",
            "Epoch 7/550\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.6595 - acc: 0.6563\n",
            "Epoch 8/550\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.6503 - acc: 0.6576\n",
            "Epoch 9/550\n",
            "768/768 [==============================] - 0s 363us/step - loss: 0.6366 - acc: 0.6641\n",
            "Epoch 10/550\n",
            "768/768 [==============================] - 0s 367us/step - loss: 0.6101 - acc: 0.6875\n",
            "Epoch 11/550\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.5997 - acc: 0.6667\n",
            "Epoch 12/550\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.6085 - acc: 0.6732\n",
            "Epoch 13/550\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.5867 - acc: 0.7083\n",
            "Epoch 14/550\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.5833 - acc: 0.6966\n",
            "Epoch 15/550\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.5787 - acc: 0.7161\n",
            "Epoch 16/550\n",
            "768/768 [==============================] - 0s 339us/step - loss: 0.5669 - acc: 0.7148\n",
            "Epoch 17/550\n",
            "768/768 [==============================] - 0s 334us/step - loss: 0.5668 - acc: 0.7057\n",
            "Epoch 18/550\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.5716 - acc: 0.7083\n",
            "Epoch 19/550\n",
            "768/768 [==============================] - 0s 379us/step - loss: 0.5567 - acc: 0.7214\n",
            "Epoch 20/550\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.5591 - acc: 0.7135\n",
            "Epoch 21/550\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.5605 - acc: 0.7253\n",
            "Epoch 22/550\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5647 - acc: 0.6979\n",
            "Epoch 23/550\n",
            "768/768 [==============================] - 0s 366us/step - loss: 0.5512 - acc: 0.7240\n",
            "Epoch 24/550\n",
            "768/768 [==============================] - 0s 342us/step - loss: 0.5513 - acc: 0.7305\n",
            "Epoch 25/550\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.5456 - acc: 0.7240\n",
            "Epoch 26/550\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.5514 - acc: 0.7174\n",
            "Epoch 27/550\n",
            "768/768 [==============================] - 0s 388us/step - loss: 0.5512 - acc: 0.7240\n",
            "Epoch 28/550\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.5504 - acc: 0.7292\n",
            "Epoch 29/550\n",
            "768/768 [==============================] - 0s 344us/step - loss: 0.5381 - acc: 0.7344\n",
            "Epoch 30/550\n",
            "768/768 [==============================] - 0s 371us/step - loss: 0.5401 - acc: 0.7422\n",
            "Epoch 31/550\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.5475 - acc: 0.7409\n",
            "Epoch 32/550\n",
            "768/768 [==============================] - 0s 369us/step - loss: 0.5506 - acc: 0.7135\n",
            "Epoch 33/550\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.5402 - acc: 0.7279\n",
            "Epoch 34/550\n",
            "768/768 [==============================] - 0s 383us/step - loss: 0.5450 - acc: 0.7461\n",
            "Epoch 35/550\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.5411 - acc: 0.7305\n",
            "Epoch 36/550\n",
            "768/768 [==============================] - 0s 341us/step - loss: 0.5398 - acc: 0.7109\n",
            "Epoch 37/550\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.5370 - acc: 0.7318\n",
            "Epoch 38/550\n",
            "768/768 [==============================] - 0s 362us/step - loss: 0.5347 - acc: 0.7292\n",
            "Epoch 39/550\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.5356 - acc: 0.7344\n",
            "Epoch 40/550\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.5252 - acc: 0.7305\n",
            "Epoch 41/550\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5396 - acc: 0.7370\n",
            "Epoch 42/550\n",
            "768/768 [==============================] - 0s 352us/step - loss: 0.5268 - acc: 0.7409\n",
            "Epoch 43/550\n",
            "768/768 [==============================] - 0s 339us/step - loss: 0.5377 - acc: 0.7409\n",
            "Epoch 44/550\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.5216 - acc: 0.7513\n",
            "Epoch 45/550\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5220 - acc: 0.7409\n",
            "Epoch 46/550\n",
            "768/768 [==============================] - 0s 376us/step - loss: 0.5228 - acc: 0.7435\n",
            "Epoch 47/550\n",
            "768/768 [==============================] - 0s 353us/step - loss: 0.5273 - acc: 0.7370\n",
            "Epoch 48/550\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.5261 - acc: 0.7422\n",
            "Epoch 49/550\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5240 - acc: 0.7370\n",
            "Epoch 50/550\n",
            "768/768 [==============================] - 0s 340us/step - loss: 0.5291 - acc: 0.7474\n",
            "Epoch 51/550\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.5187 - acc: 0.7474\n",
            "Epoch 52/550\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.5151 - acc: 0.7461\n",
            "Epoch 53/550\n",
            "768/768 [==============================] - 0s 357us/step - loss: 0.5201 - acc: 0.7370\n",
            "Epoch 54/550\n",
            "768/768 [==============================] - 0s 370us/step - loss: 0.5177 - acc: 0.7552\n",
            "Epoch 55/550\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.5275 - acc: 0.7474\n",
            "Epoch 56/550\n",
            "768/768 [==============================] - 0s 375us/step - loss: 0.5322 - acc: 0.7422\n",
            "Epoch 57/550\n",
            "768/768 [==============================] - 0s 377us/step - loss: 0.5102 - acc: 0.7578\n",
            "Epoch 58/550\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.5107 - acc: 0.7474\n",
            "Epoch 59/550\n",
            "768/768 [==============================] - 0s 389us/step - loss: 0.5146 - acc: 0.7565\n",
            "Epoch 60/550\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.5227 - acc: 0.7474\n",
            "Epoch 61/550\n",
            "768/768 [==============================] - 0s 339us/step - loss: 0.5065 - acc: 0.7370\n",
            "Epoch 62/550\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.5102 - acc: 0.7591\n",
            "Epoch 63/550\n",
            "768/768 [==============================] - 0s 386us/step - loss: 0.5241 - acc: 0.7344\n",
            "Epoch 64/550\n",
            "768/768 [==============================] - 0s 349us/step - loss: 0.5120 - acc: 0.7552\n",
            "Epoch 65/550\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.5073 - acc: 0.7617\n",
            "Epoch 66/550\n",
            "768/768 [==============================] - 0s 384us/step - loss: 0.5162 - acc: 0.7474\n",
            "Epoch 67/550\n",
            "768/768 [==============================] - 0s 378us/step - loss: 0.5146 - acc: 0.7474\n",
            "Epoch 68/550\n",
            "768/768 [==============================] - 0s 387us/step - loss: 0.5065 - acc: 0.7617\n",
            "Epoch 69/550\n",
            "768/768 [==============================] - 0s 354us/step - loss: 0.5005 - acc: 0.7487\n",
            "Epoch 70/550\n",
            "768/768 [==============================] - 0s 365us/step - loss: 0.5069 - acc: 0.7604\n",
            "Epoch 71/550\n",
            "768/768 [==============================] - 0s 409us/step - loss: 0.5190 - acc: 0.7448\n",
            "Epoch 72/550\n",
            "768/768 [==============================] - 0s 414us/step - loss: 0.5016 - acc: 0.7513\n",
            "Epoch 73/550\n",
            "768/768 [==============================] - 0s 391us/step - loss: 0.5042 - acc: 0.7526\n",
            "Epoch 74/550\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.5013 - acc: 0.7617\n",
            "Epoch 75/550\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.5087 - acc: 0.7656\n",
            "Epoch 76/550\n",
            "768/768 [==============================] - 0s 385us/step - loss: 0.4939 - acc: 0.7604\n",
            "Epoch 77/550\n",
            "768/768 [==============================] - 0s 356us/step - loss: 0.5177 - acc: 0.7409\n",
            "Epoch 78/550\n",
            "768/768 [==============================] - 0s 361us/step - loss: 0.5135 - acc: 0.7578\n",
            "Epoch 79/550\n",
            "768/768 [==============================] - 0s 372us/step - loss: 0.4910 - acc: 0.7721\n",
            "Epoch 80/550\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.5014 - acc: 0.7539\n",
            "Epoch 81/550\n",
            "768/768 [==============================] - 0s 374us/step - loss: 0.4998 - acc: 0.7578\n",
            "Epoch 82/550\n",
            "768/768 [==============================] - 0s 351us/step - loss: 0.4959 - acc: 0.7708\n",
            "Epoch 83/550\n",
            "768/768 [==============================] - 0s 339us/step - loss: 0.4924 - acc: 0.7604\n",
            "Epoch 84/550\n",
            "768/768 [==============================] - 0s 359us/step - loss: 0.4866 - acc: 0.7526\n",
            "Epoch 85/550\n",
            "768/768 [==============================] - 0s 358us/step - loss: 0.4975 - acc: 0.7630\n",
            "Epoch 86/550\n",
            "768/768 [==============================] - 0s 364us/step - loss: 0.4873 - acc: 0.7747\n",
            "Epoch 87/550\n",
            "768/768 [==============================] - 0s 360us/step - loss: 0.4858 - acc: 0.7760\n",
            "Epoch 88/550\n",
            "768/768 [==============================] - 0s 355us/step - loss: 0.4861 - acc: 0.7591\n",
            "Epoch 89/550\n",
            "590/768 [======================>.......] - ETA: 0s - loss: 0.4943 - acc: 0.7576"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-5-6e3c0411aa88>\", line 19, in <module>\n",
            "    model.fit(X, y, epochs=550, batch_size=10)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1178, in fit\n",
            "    validation_freq=validation_freq)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 204, in fit_loop\n",
            "    outs = fit_function(ins_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2979, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2937, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 47, in <module>\n",
            "    from tensorflow.contrib import distributions\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 29, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops import bijectors\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 44, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops.estimator import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/python/ops/estimator.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/__init__.py\", line 93, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/__init__.py\", line 28, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/__init__.py\", line 30, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import estimators\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/__init__.py\", line 302, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py\", line 34, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 36, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 52, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/__init__.py\", line 26, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/dask_io.py\", line 33, in <module>\n",
            "    import dask.dataframe as dd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/__init__.py\", line 2, in <module>\n",
            "    from .core import (\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/core.py\", line 25, in <module>\n",
            "    from .. import array as da\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/array/__init__.py\", line 26, in <module>\n",
            "    from .routines import (\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/array/routines.py\", line 1280, in <module>\n",
            "    @derived_from(np)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/utils.py\", line 675, in wrapper\n",
            "    original_klass, method, ua_args=ua_args, extra=extra\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/utils.py\", line 647, in _derived_from\n",
            "    doc = extra_titles(doc)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/utils.py\", line 548, in extra_titles\n",
            "    lines = doc.split(\"\\n\")\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_IUPvEIHBXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L3jix7GLC8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}